{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (7.2.0)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (6.29.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter) (8.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (8.6.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipywidgets->jupyter) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipywidgets->jupyter) (3.0.11)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-console->jupyter) (3.0.45)\n",
      "Requirement already satisfied: pygments in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-console->jupyter) (2.18.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbconvert->jupyter) (1.3.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from notebook->jupyter) (2.14.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from notebook->jupyter) (2.27.2)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from notebook->jupyter) (4.2.1)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from notebook->jupyter) (0.2.4)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (306)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.4.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.20.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.13)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2.2.5)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2.15.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (4.22.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2.32.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.19.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (0.18.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->jupyter) (2.2.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.9.0.20240316)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pyts in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pyts) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pyts) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pyts) (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pyts) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.55.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pyts) (0.59.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from numba>=0.55.2->pyts) (0.42.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from scikit-learn>=1.2.0->pyts) (3.5.0)\n",
      "Name: ipython\n",
      "Version: 8.24.0\n",
      "Summary: IPython: Productive Interactive Computing\n",
      "Home-page: \n",
      "Author: The IPython Development Team\n",
      "Author-email: ipython-dev@python.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages\n",
      "Requires: colorama, decorator, exceptiongroup, jedi, matplotlib-inline, prompt-toolkit, pygments, stack-data, traitlets, typing-extensions\n",
      "Required-by: ipykernel, ipywidgets, jupyter-console\n",
      "Name: nbformat\n",
      "Version: 5.10.4\n",
      "Summary: The Jupyter Notebook format\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Jupyter Development Team <jupyter@googlegroups.com>\n",
      "License: BSD 3-Clause License\n",
      "        \n",
      "        - Copyright (c) 2001-2015, IPython Development Team\n",
      "        - Copyright (c) 2015-, Jupyter Development Team\n",
      "        \n",
      "        All rights reserved.\n",
      "        \n",
      "        Redistribution and use in source and binary forms, with or without\n",
      "        modification, are permitted provided that the following conditions are met:\n",
      "        \n",
      "        1. Redistributions of source code must retain the above copyright notice, this\n",
      "           list of conditions and the following disclaimer.\n",
      "        \n",
      "        2. Redistributions in binary form must reproduce the above copyright notice,\n",
      "           this list of conditions and the following disclaimer in the documentation\n",
      "           and/or other materials provided with the distribution.\n",
      "        \n",
      "        3. Neither the name of the copyright holder nor the names of its\n",
      "           contributors may be used to endorse or promote products derived from\n",
      "           this software without specific prior written permission.\n",
      "        \n",
      "        THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "        AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "        IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "        DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "        FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "        DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "        SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "        CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "        OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "        OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages\n",
      "Requires: fastjsonschema, jsonschema, jupyter-core, traitlets\n",
      "Required-by: jupyter_server, nbclient, nbconvert\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: plotly in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (5.22.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from plotly) (8.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from plotly) (24.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: yfinance in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (0.2.40)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (5.2.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (4.2.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (3.17.5)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sergio\\aaa\\module_25\\req-act-25-3-project-jp\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter\n",
    "!pip install pyts\n",
    "!pip install nbformat>=4.2.0\n",
    "!pip show ipython\n",
    "!pip show nbformat\n",
    "!pip install --upgrade plotly\n",
    "\n",
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "Device cuda:0\n",
      "cuda version 12.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import floor\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import yfinance as yf\n",
    "\n",
    "import torch.backends.cudnn\n",
    "\n",
    "#set gpu env\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\",device)\n",
    "print(\"cuda version\",torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close price time period\n",
    "start_date = '2021-10-01'\n",
    "end_date = '2023-12-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows 524\n",
      "Num rows for df Close col 524\n",
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "2021-10-01  650.000000  669.570007  648.065002  664.530029  664.530029  281112\n",
      "2021-10-04  663.989990  669.000000  645.729797  649.349976  649.349976  340741\n",
      "2021-10-05  657.909973  669.174988  652.072571  665.380005  665.380005  358684\n",
      "2021-10-06  654.039978  663.919983  643.219971  659.849976  659.849976  441251\n",
      "2021-10-07  670.929993  679.000000  663.280029  665.559998  665.559998  258661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ticker = 'SIVBQ'\n",
    "dataset = yf.download(ticker, start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "print(\"num rows\",dataset.shape[0])\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "print(\"Num rows for df Close col\",len(dataset['Close'].dropna()))\n",
    "print(dataset.head())\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')\n",
    "# pd.reset_option('display.width')\n",
    "# pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset\n",
    "\n",
    "Drop row if column is either NaN or missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Gramian angular field (GAF) images from time series data \n",
    "Uses popular time series imaging algorithm in [pyts' GramianAngularField method](https://pyts.readthedocs.io/en/stable/auto_examples/image/plot_single_gaf.html)\n",
    "\n",
    "GAF represents time series in a polar coordinate system instead of the typical Cartesian coordinates by considering the trigonometric sum or difference between stock prices and calculate the correlation within different time intervals. [Source.](https://towardsdatascience.com/rgb-gaf-image-a-possible-solution-to-one-weak-point-of-gramian-angular-field-imaging-ffc6b31edfbe)\n",
    "\n",
    "[Making Gram matrix CNN ready](https://medium.com/analytics-vidhya/encoding-time-series-as-images-b043becbdbf3)\n",
    "\n",
    "The dot product operation in GAF provides us with the similarity between datapoints. Since GAF provides the combination of the datapoints requested, the dot product combination of 32 data points yields 1024 points in an image. Since we request GAF images of size 32x32, we can calculate the number of images GAF will generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaf_images(dataset, gaf_img_sz=32, method=\"summation\", sample_range=(0,1)):\n",
    "    #print(\"len data series received:\",len(dataset),\"size\",dataset.size)\n",
    "\n",
    "    #determine num of gaf_img_szX images with gaf_img_sz datapoints\n",
    "    num_images_to_generate = floor(len(dataset) / gaf_img_sz)\n",
    "    #print(\"num_images_to_generate\",num_images_to_generate)\n",
    "    \n",
    "    #reshape dataset into number of images\n",
    "    dataset = dataset[:num_images_to_generate*gaf_img_sz].reshape(num_images_to_generate, gaf_img_sz)\n",
    "    #print(\"data in GAF\",dataset)\n",
    "    \n",
    "    price_list=[]\n",
    "    for i in range(num_images_to_generate):\n",
    "        price_list.append(np.mean(dataset[i]))\n",
    "    #print(\"prices in GAF\",price_list)\n",
    "    #print(\"image_size\",gaf_img_sz)\n",
    "    \n",
    "    gaf = GramianAngularField(image_size=gaf_img_sz, method=method, sample_range=sample_range)\n",
    "    gaf_images= gaf.fit_transform(dataset)\n",
    "    #print(\"gaf_image\",gaf_images.shape)\n",
    "    \n",
    "    return gaf_images, price_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Closing Price for one image in GAF\n",
    "A darker patch indicates lower correlation between the different elements of the price time series, possibly due to higher volatility or noise. The opposite is true for the lighter patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524\n",
      " (16, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gaf_method='summation'\n",
    "\n",
    "feature_data = np.array(dataset['Close'])\n",
    "print(len(dataset['Close']))\n",
    "#print(\"feature_dataset_array\",feature_data)\n",
    "#print(\"len datapoints in dataset\",len(feature_data))\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "gaf_images,price_list= generate_gaf_images(feature_data,gaf_img_sz=32, method=gaf_method)\n",
    "\n",
    "print(\"\",gaf_images.shape)\n",
    "plt.imshow(gaf_images[0],cmap='hot')\n",
    "#print(\"gaf_images.shape\",gaf_images.shape,\"data points in images\",gaf_images.size, \"gaf image [0] shape\",gaf_images[0].shape, \"data points in image [0]\",gaf_images[0].size)\n",
    "#print(\"gasf image[0] data\",gaf_images[0])\n",
    "#print(\"Gasf data\",gasf_images)\n",
    "\n",
    "np.set_printoptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images for open, high, low, close and adj close prices\n",
    "\n",
    "We transpose the resulting image list to represent:\n",
    "+ 16: number of images\n",
    "+ 5: number of image channels/features. Each image has 5 =\"Open\", \"High\", \"Low\", \"Close\", and \"Adj Close\"\n",
    "+ 32: image height\n",
    "+ 32: image width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Open 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature High 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Low 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Close 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Adj Close 491\n",
      "len images 5 len price list 5 len labels 491\n",
      "Shape of images before transpose: (5, 1, 491, 1, 32, 32)\n",
      "Shape of images after transpose: (1, 1, 5, 491, 32, 32)\n",
      "shape [0] set (1, 5, 491, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "cols_used = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]\n",
    "cols_used_count = sum(column_name in cols_used for column_name in dataset.columns)\n",
    "\n",
    "def generate_multiple_feature_images(dataset, image_size=32, method=\"summation\", sample_range = (0, 1)):\n",
    "    \n",
    "    feature_image_dataset_list=[[] for _ in range(len(cols_used))]\n",
    "    feature_price_dataset_list=[[] for _ in range(len(cols_used))] #=\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    feature_label_dataset_list=[] #next value for each chunk of =\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    \n",
    "    column_idx = 0\n",
    "\n",
    "    for idx, column_name in enumerate(dataset.columns):\n",
    "\n",
    "      #create open, high, low and close images\n",
    "      if column_name in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]:\n",
    "        temp_image_list = []\n",
    "        temp_price_list = []\n",
    "        #print(\"dataset idx\", idx, \"len rows this data feature\", len(dataset[i]), \"dataset[i].shape\", dataset[i].shape, \"dataset i:\", dataset[i])\n",
    "\n",
    "        feature_data = dataset[column_name].values\n",
    "        num_samples = len(feature_data)\n",
    "        print(\"num_samples\",num_samples)\n",
    "\n",
    "        #print(\"feature_dataset_array idx\", idx, \"len rows feature_dataset_array\", len(feature_dataset_array[0]), \"shape\",feature_dataset_array.shape, \"feature_dataset_array:\", feature_dataset_array)\n",
    "        \n",
    "        # generate_gaf_images generates images from full dataset according to image_size\n",
    "        # however, we loop by data_chunk so each chunk represents the price series that we slide by one day forward\n",
    "        # and generate an image for each slice\n",
    "        # TODO: parallelism\n",
    "        # we add cushion to slide the window forward\n",
    "        print(f\"Target number of chunks to create an image for Feature {column_name}\",num_samples - (image_size+1))\n",
    "        for cur_chunk in range(num_samples - (image_size+1)):\n",
    "          \n",
    "          #chunk size of image size\n",
    "          data_chunk = feature_data[cur_chunk:cur_chunk+image_size]\n",
    "          \n",
    "          #append gaf image to image list. store price feature values in price list\n",
    "          gaf_images, price_list = generate_gaf_images(data_chunk, gaf_img_sz=image_size, method=method, sample_range=sample_range)\n",
    "          temp_image_list.append(gaf_images)\n",
    "          \n",
    "          # if(cur_chunk==0):\n",
    "          #   print(\"Price Data Pre-Gaf: i\", cur_chunk, \"len\",len(data_chunk), \"shape\", feature_data.shape, \"data\",data_chunk)\n",
    "          #   print(\"Image Returned: idx\", idx, \"image size\", gaf_images.size, f\"first {image_size} image vals\", gaf_images.flatten()[:image_size])\n",
    "          \n",
    "          temp_price_list.append(price_list)\n",
    "          \n",
    "          #get next single value after the chunk as label to list\n",
    "          if(column_name == \"Open\"):\n",
    "            feature_label_dataset_list.append(cur_chunk + image_size + 1)\n",
    "        \n",
    "        feature_image_dataset_list[column_idx].append(temp_image_list)\n",
    "        feature_price_dataset_list[column_idx].append(price_list)\n",
    "        column_idx += 1\n",
    "\n",
    "\n",
    "    print(\"len images\",len(feature_image_dataset_list),\"len price list\",len(feature_price_dataset_list), \"len labels\", len(feature_label_dataset_list)) # 2455=total range*5\n",
    "    \n",
    "    feature_image_dataset_list = np.array(feature_image_dataset_list) \n",
    "    print(\"Shape of images before transpose:\", feature_image_dataset_list.shape)\n",
    "    \n",
    "    #transpose image for CNN\n",
    "    #(5, 1, 491, 1, 32, 32)\n",
    "    feature_image_dataset_list= np.transpose(feature_image_dataset_list, (1, 3, 0, 2, 4, 5))\n",
    "    print(\"Shape of images after transpose:\", feature_image_dataset_list.shape)\n",
    "\n",
    "    return feature_image_dataset_list, feature_price_dataset_list, feature_label_dataset_list\n",
    "\n",
    "#Generate images from dataset\n",
    "gaf_method=\"summation\"\n",
    "sample_range = (0, 1)\n",
    "image_size = 32 #(x,y)\n",
    "feature_image_dataset_list, feature_price_dataset_list, feature_label_dataset_list = generate_multiple_feature_images(dataset, image_size=image_size, method=gaf_method, sample_range=sample_range)\n",
    "\n",
    "print(\"shape [0] set\",np.array(feature_image_dataset_list[0]).shape)\n",
    "\n",
    "np.set_printoptions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual representation of feature images for the same time range\n",
    "\n",
    "Bottom image averages depth values of feature images (channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape images array (1, 1, 5, 491, 32, 32) shape image (32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_array=np.array(feature_image_dataset_list)\n",
    "prices_array=np.array(feature_price_dataset_list)\n",
    "labels_array=np.array(feature_label_dataset_list)\n",
    "\n",
    "# Plot the first image of each column\n",
    "fig, axes = plt.subplots(nrows=1, ncols=cols_used_count, figsize=(20, 6))\n",
    "for ax in axes:\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "#EXPLANATION SHAPE\n",
    "#shape images array (1, 1, 5, 491, 32, 32)\n",
    "#I get 16 images (32x32) for 524 data points, i.e. close full price series.\n",
    "#Since I create images for a sliding window of price series, I request ~30 time series into images\n",
    "#30*16=480~491 -  difference due to smaller last window\n",
    "print(\"shape images array\",images_array.shape,\"shape image\",images_array[0][0][0][0].shape)\n",
    "for i in range(cols_used_count):\n",
    "    axes[i].imshow(images_array[0][0][i][0], cmap='hot')\n",
    "    axes[i].set_title(f\"Column {cols_used[i]} \")\n",
    "\n",
    "#average first image of all features\n",
    "#interval_between_features = images_array[0][0][0][0][0].shape\n",
    "average_images = []\n",
    "for i in range(cols_used_count):\n",
    "    average_images.append(images_array[0][0][i][0])\n",
    "    #print(\"this image shape\",images_array[0, image_index].shape)\n",
    "\n",
    "average_image = np.mean(average_images, axis=0)\n",
    "\n",
    "# Hide axes\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "# Plot the average image separately\n",
    "plt.figure()  # Create a new figure for the average image\n",
    "plt.imshow(average_image, cmap='hot')\n",
    "plt.title(\"Average Image\")\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training/Testing Datasets for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Transform to image to convert to tensor and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetTransform(normalize_ftor=0.5,resolution_x=32,resolution_y=32):\n",
    "    return transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([normalize_ftor], [normalize_ftor])\n",
    "    #transforms.Resize((resolution_x, resolution_y))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 5, 491, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "feature_image_dataset_list_f32 = np.array(images_array).astype(np.float32)\n",
    "#images_array = np.transpose(feature_image_dataset_list, (1, 0, 2, 3))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "labels_array = np.array(labels_array)#.astype(np.float32)\n",
    "reshaped_labels_array = labels_array.reshape(-1, 1)\n",
    "labels_scaled_list_f32 = scaler.fit_transform(reshaped_labels_array).reshape(-1,).astype(np.float32)\n",
    "\n",
    "print(images_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare features data (close, high, low, etc) for Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrep(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.transform = SetTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.inputs[index]\n",
    "        Y = self.labels[index]\n",
    "        return X, Y\n",
    "  \n",
    "    def prepare_ordered_dataset(self):\n",
    "        x = []\n",
    "        y = []\n",
    "        #print(\"len inputs\", len(self.inputs), self.inputs.shape, self.inputs.shape[0])\n",
    "        for feature in range(self.inputs.shape[0]):\n",
    "            #print(\"feature\",feature,self.inputs[feature].shape[0])\n",
    "            for image in range(self.inputs[feature].shape[0]):\n",
    "                #print(\"feature-image\",feature,image,\"len image\",len(self.inputs[feature][image]))\n",
    "                #print(\"size image\",self.inputs[feature][image].size)\n",
    "                #print(\"label\",self.labels[image])\n",
    "                self.inputs[feature][image] = self.transform(self.inputs[feature][image])\n",
    "                x.append(np.expand_dims(self.inputs[feature][image], axis=0))\n",
    "                y.append(self.labels[image])\n",
    "                #print(self.labels[image])\n",
    "                #print(self.inputs[feature][image].shape)\n",
    "        \n",
    "        #cnn requests labels size (4,1) instead of (4)\n",
    "        y = np.expand_dims(y, axis=1) \n",
    "        #print(\"size self\",self.inputs[0].shape,self.inputs[1].shape)\n",
    "        dataset = [(img, label) for img, label in zip(x, y)]\n",
    "        return dataset\n",
    "        \n",
    "        #return np.array(x),np.array(y)\n",
    "    \n",
    "    def split_data(self,dataset, batch_size=10, test_size=0.2, train_shuffle=False):\n",
    "        num_samples = len(dataset)\n",
    "        #print(\"numsamples\",num_samples)\n",
    "        num_test_samples = int(test_size * num_samples)\n",
    "        num_train_samples = num_samples - num_test_samples\n",
    "        #print(\"num_train_samples\",num_train_samples)\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        train_indices = indices[:num_train_samples]\n",
    "        test_indices = indices[num_train_samples:]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler,shuffle=train_shuffle)\n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "        sample_batch = next(iter(train_loader))\n",
    "        input_shape = sample_batch[0].shape\n",
    "        label_shape = sample_batch[1].shape\n",
    "        print(\"input_shape\",input_shape,\"label_shape\",label_shape)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 491, 32, 32) 5\n",
      "input_shape torch.Size([10, 1, 32, 32]) label_shape torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "def Generate_Train_And_Test_Loaders(feature_image_dataset_list_f32,labels_scaled_list_f32, train_shuffle=False, batch_size=10):\n",
    "\n",
    "    print(feature_image_dataset_list_f32[0][0].shape, feature_image_dataset_list_f32[0][0].shape[0])\n",
    "\n",
    "    #reshape for cnn\n",
    "    reshaped_feature_image_dataset_list_f32 = np.expand_dims(feature_image_dataset_list_f32[0][0].reshape(-1, *feature_image_dataset_list_f32[0][0].shape[2:]), axis=1)\n",
    "    #print(\"res\",reshaped_feature_image_dataset_list_f32.shape)\n",
    "\n",
    "    dataPreObject = DataPrep(reshaped_feature_image_dataset_list_f32, labels_scaled_list_f32)\n",
    "    #print(\"dataprep image:\",dataPreObject[0][0].shape,\"label\",dataPreObject[0][1].size)\n",
    "\n",
    "    #print(\"feature_image_dataset_list_f32\",feature_image_dataset_list_f32[0][0].shape)\n",
    "    #print(\"labels_scaled_list_f32\",labels_scaled_list_f32.shape)\n",
    "    dataset = dataPreObject.prepare_ordered_dataset()\n",
    "\n",
    "    # for c in range(len(dataset[0])):\n",
    "    #     print(f\"size labels {c}\",dataset[1][c].size)\n",
    "    #     print(f\"size image {c}\",dataset[0][c].shape)\n",
    "\n",
    "    batch_size = batch_size\n",
    "    train_loader, test_loader = dataPreObject.split_data(dataset, \n",
    "                                                         batch_size=batch_size,\n",
    "                                                         train_shuffle=train_shuffle)\n",
    "\n",
    "    # for e in train_loader:\n",
    "    #     print(\"type\",type(e))\n",
    "    #     print(\"imga\",e[0].shape,e[0].size)\n",
    "    #     print(\"label\",e[1].shape,e[1].size)\n",
    "\n",
    "    return train_loader,test_loader\n",
    "    \n",
    "\n",
    "train_loader,test_loader = Generate_Train_And_Test_Loaders(feature_image_dataset_list_f32,labels_scaled_list_f32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamically calulate the shape of layers outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_shape_dynamic(h_w, kernel_size=(1,1), stride=1):\n",
    "        h = floor( (h_w[0] - kernel_size[0])/ stride) + 1\n",
    "        w = floor( (h_w[1] - kernel_size[1])/ stride) + 1\n",
    "        return h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,name=\"LeNet5Blend\",\n",
    "                 filter_size_1=(2, 2), filter_size_2=(2, 3), filter_size_3=(2, 3), stride=2,\n",
    "                 output_conv_1=80,output_conv_2=16, output_FC_1=120,output_FC_2=84,\n",
    "                 image_resolution_x=32,image_resolution_y=32,final_FCLayer_outputs=1,\n",
    "                 dropout_probab=0):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        if name:\n",
    "            self.name = name\n",
    "        self.totalparams = 0\n",
    "        self.output_conv_2=output_conv_2\n",
    "        self.conv_output_size=0\n",
    "        print();print(\"Convos & dropoutP:\",output_conv_1,output_conv_2, dropout_probab)\n",
    "        \n",
    "        #num channels input, num channels output, filter size \n",
    "        self.conv1 = nn.Conv2d(1, output_conv_1, filter_size_1,stride=1)\n",
    "        #filtersize,stride.\n",
    "        #maxpool acts the same way in each channel, so doesn't need to be fed the num channels of the input\n",
    "        self.pool = nn.MaxPool2d(kernel_size=filter_size_2, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(output_conv_1, output_conv_2, filter_size_3,stride=1)\n",
    "\n",
    "        H_out_1, W_out_1 = conv_output_shape_dynamic((image_resolution_y, image_resolution_x), kernel_size=filter_size_1,stride=1)\n",
    "        H_out_2, W_out_2 = conv_output_shape_dynamic((H_out_1, W_out_1), kernel_size=filter_size_2,stride=stride)\n",
    "        H_out_3, W_out_3 = conv_output_shape_dynamic((H_out_2, W_out_2), kernel_size=filter_size_3,stride=1)\n",
    "        H_out_4, W_out_4 = conv_output_shape_dynamic((H_out_3, W_out_3), kernel_size=filter_size_2,stride=stride)\n",
    "        \n",
    "        print(\"imgres\",image_resolution_x,image_resolution_y)\n",
    "        print(\"H_out_1, W_out_1\",H_out_1, W_out_1)\n",
    "        print(\"H_out_2, W_out_2\",H_out_2, W_out_2)\n",
    "        print(\"H_out_3, W_out_4\",H_out_3, W_out_3)\n",
    "        print(\"H_out_4, W_out_4\",H_out_4, W_out_4)\n",
    "        print(\"outputconv2\",output_conv_2)\n",
    "        self.conv_output_size = H_out_4 * W_out_4\n",
    "\n",
    "        #Fully connected layers and apply dropout\n",
    "        self.fc1 = nn.Linear(output_conv_2*self.conv_output_size, output_FC_1)\n",
    "        if(dropout_probab>0): self.dropout1 = nn.Dropout(dropout_probab)\n",
    "        self.fc2 = nn.Linear(output_FC_1, output_FC_2)\n",
    "        if(dropout_probab>0): self.dropout1 = nn.Dropout(dropout_probab)\n",
    "        self.fc3 = nn.Linear(output_FC_2, final_FCLayer_outputs)\n",
    "        \n",
    "        # compute the total number of parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(self.name + ': total params:', total_params)\n",
    "        self.totalparams=total_params\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"Input shape:\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(\"After conv1 and pooling shape:\", x.shape)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(\"After conv2 and pooling shape:\", x.shape)\n",
    "        #-1 takes the batch size\n",
    "        x = x.view(-1,self.output_conv_2*self.conv_output_size)\n",
    "        #print(\"After flattening shape:\", x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(\"After fc1 shape:\", x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(\"After fc2 shape:\", x.shape)\n",
    "        x = self.fc3(x)\n",
    "        #print(\"Output shape:\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default hyperparameters\n",
    "\n",
    "filter_size_1=(2, 2)\n",
    "filter_size_2=(2, 3)\n",
    "filter_size_3=(2, 3)\n",
    "\n",
    "stride=2\n",
    "\n",
    "output_conv_1=40\n",
    "output_conv_2=12\n",
    "output_FC_1=100\n",
    "output_FC_2=70\n",
    "final_FCLayer_output=1\n",
    "\n",
    "learning_rate=0.001\n",
    "momentum = 0.9\n",
    "\n",
    "dropout_probab=0\n",
    "\n",
    "num_epochs_input = 20\n",
    "\n",
    "transform = SetTransform(normalize_ftor=0.5, resolution_x=32, resolution_y=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Convos & dropoutP: 40 12 0\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 12\n",
      "Classification Net: total params: 60733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x00000189288A6EA0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(name='Classification Net', filter_size_1=filter_size_1, filter_size_2=filter_size_2,\n",
    "            filter_size_3=filter_size_3, stride=stride,\n",
    "            image_resolution_x=32,image_resolution_y=32,\n",
    "            output_conv_1=output_conv_1, output_conv_2=output_conv_2,\n",
    "            output_FC_1=output_FC_1, output_FC_2=output_FC_2,\n",
    "            final_FCLayer_outputs=final_FCLayer_output,\n",
    "            dropout_probab=dropout_probab)\n",
    "\n",
    "net.to(device)\n",
    "net.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train params: 0.001 0.9\n",
      "[1,    50] Cum loss: 0.323329\n",
      "[1,   100] Cum loss: 0.029213\n",
      "[1,   150] Cum loss: 0.016441\n",
      "[2,    50] Cum loss: 0.004409\n",
      "[2,   100] Cum loss: 0.002072\n",
      "[2,   150] Cum loss: 0.002512\n",
      "[3,    50] Cum loss: 0.001937\n",
      "[3,   100] Cum loss: 0.001668\n",
      "[3,   150] Cum loss: 0.001260\n",
      "[4,    50] Cum loss: 0.001500\n",
      "[4,   100] Cum loss: 0.001097\n",
      "[4,   150] Cum loss: 0.000947\n",
      "[5,    50] Cum loss: 0.000829\n",
      "[5,   100] Cum loss: 0.001106\n",
      "[5,   150] Cum loss: 0.001017\n",
      "[6,    50] Cum loss: 0.000694\n",
      "[6,   100] Cum loss: 0.000751\n",
      "[6,   150] Cum loss: 0.000710\n",
      "[7,    50] Cum loss: 0.001266\n",
      "[7,   100] Cum loss: 0.000697\n",
      "[7,   150] Cum loss: 0.001367\n",
      "[8,    50] Cum loss: 0.000982\n",
      "[8,   100] Cum loss: 0.000522\n",
      "[8,   150] Cum loss: 0.000680\n",
      "[9,    50] Cum loss: 0.000727\n",
      "[9,   100] Cum loss: 0.000376\n",
      "[9,   150] Cum loss: 0.000530\n",
      "[10,    50] Cum loss: 0.000426\n",
      "[10,   100] Cum loss: 0.000553\n",
      "[10,   150] Cum loss: 0.000521\n",
      "[11,    50] Cum loss: 0.000746\n",
      "[11,   100] Cum loss: 0.000480\n",
      "[11,   150] Cum loss: 0.000595\n",
      "[12,    50] Cum loss: 0.000545\n",
      "[12,   100] Cum loss: 0.000467\n",
      "[12,   150] Cum loss: 0.000461\n",
      "[13,    50] Cum loss: 0.000440\n",
      "[13,   100] Cum loss: 0.000559\n",
      "[13,   150] Cum loss: 0.000404\n",
      "[14,    50] Cum loss: 0.000353\n",
      "[14,   100] Cum loss: 0.000311\n",
      "[14,   150] Cum loss: 0.000505\n",
      "[15,    50] Cum loss: 0.000755\n",
      "[15,   100] Cum loss: 0.000932\n",
      "[15,   150] Cum loss: 0.000629\n",
      "[16,    50] Cum loss: 0.000627\n",
      "[16,   100] Cum loss: 0.000654\n",
      "[16,   150] Cum loss: 0.000566\n",
      "[17,    50] Cum loss: 0.002657\n",
      "[17,   100] Cum loss: 0.001202\n",
      "[17,   150] Cum loss: 0.000283\n",
      "[18,    50] Cum loss: 0.000528\n",
      "[18,   100] Cum loss: 0.000266\n",
      "[18,   150] Cum loss: 0.000358\n",
      "[19,    50] Cum loss: 0.000462\n",
      "[19,   100] Cum loss: 0.000473\n",
      "[19,   150] Cum loss: 0.000469\n",
      "[20,    50] Cum loss: 0.000744\n",
      "[20,   100] Cum loss: 0.000382\n",
      "[20,   150] Cum loss: 0.000751\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#print running_loss every [x] mini-batches\n",
    "mini_batch_running_loss_check = 50\n",
    "\n",
    "def Train(learning_rate=learning_rate,momentum=momentum,\n",
    "          train_loader=train_loader, net=net):\n",
    "    \n",
    "    print(\"Train params:\",learning_rate,momentum)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    for epoch in range(num_epochs_input):  \n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            #get the inputs; data is a list of [inputs, labels]\n",
    "            # print(\"image type\",type(data[0]), \"shape\", data[0].shape)\n",
    "            # print(\"image size\",data[0].numel())\n",
    "            # print(\"label type\",type(data[1]), \"shape\", data[1].shape)\n",
    "            # print(\"label size\",data[1].numel())\n",
    "            #print(\"**zero:\",data[0])\n",
    "            #print(\"type\",type(data[1]),\"**one:\", data[1])\n",
    "            #print(\"label pre\",data[1])\n",
    "            #data[1]=data[1].type(torch.LongTensor)\n",
    "            #print(\"label post\",data[1])\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #print(\"at epoch\",epoch,\"at i\",i,\"emotion\",labels_emotion,\"person\",labels_person)\n",
    "            \n",
    "            # for e in data[1]:\n",
    "            #     print(\"label\",e.item())\n",
    "            #print(\"label\",data[1].item())\n",
    "            #labels = labels.long()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            #print(\"outputs\",outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Print optimizer's state_dict\n",
    "                # print(\"Optimizer's state_dict:\")\n",
    "                # for var_name in optimizer.state_dict():\n",
    "                #     print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % mini_batch_running_loss_check == (mini_batch_running_loss_check-1):    # print every 20 mini-batches\n",
    "                    print('[%d, %5d] Cum loss: %.6f' %\n",
    "                        (epoch + 1, i + 1, running_loss / mini_batch_running_loss_check)) \n",
    "                    running_loss = 0.0\n",
    "\n",
    "                if loss.item() < 0.000001:\n",
    "                    print(\"Loss is less than 0.0001. Stopping training.\")\n",
    "                    return loss\n",
    "                \n",
    "    return loss\n",
    "\n",
    "loss = Train()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(test_loader=test_loader, net=net):\n",
    "    predicted = []\n",
    "    actual = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        predicted.append(outputs)\n",
    "        actual.append(labels)\n",
    "\n",
    "        predicted_rounded = torch.round(outputs.data * 100) / 100\n",
    "        actual_rounded = torch.round(labels.data * 100) / 100\n",
    "        #print(\"predicted rounded\",predicted_rounded,\"actual rounded\",actual_rounded)\n",
    "        correct += torch.sum(torch.abs(predicted_rounded - actual_rounded) <= 0.01).item()\n",
    "        total += len(predicted_rounded)\n",
    "    #Pct correct pred\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"Percentage of predictions within 2 decimal places: {accuracy:.2f}%\")\n",
    "\n",
    "    #print(predicted,actual)\n",
    "    return predicted_rounded,actual_rounded,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of predictions within 2 decimal places: 60.69%\n",
      "   Predicted  Actual Percentage Difference\n",
      "0      -1.76   -1.73                1.734%\n",
      "Accuracy: 60.692 Average Percentage Difference: 1.734% for timeseries of 1 datapoints across 5 features: ['Open', 'High', 'Low', 'Close', 'Adj Close'].\n"
     ]
    }
   ],
   "source": [
    "predicted, actual, accuracy = Test()\n",
    "\n",
    "#predicted = torch.cat(predicted)\n",
    "#actual = torch.cat(actual)\n",
    "absolute_diff = torch.abs(predicted - actual)\n",
    "percentage_diff = (absolute_diff / torch.abs(actual)) * 100\n",
    "\n",
    "predicted_np = predicted.cpu().detach().numpy()\n",
    "actual_np = actual.cpu().detach().numpy()\n",
    "percentage_diff_np = percentage_diff.cpu().detach().numpy()\n",
    "\n",
    "# Create a dictionary with the data\n",
    "data = {\n",
    "    'Predicted': predicted_np.flatten(),\n",
    "    'Actual': actual_np.flatten(),\n",
    "    'Percentage Difference': percentage_diff_np.flatten()\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['Percentage Difference'] = df['Percentage Difference'].map(lambda x: f\"{x:.3f}%\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "df['Percentage Difference'] = df['Percentage Difference'].str.rstrip('%').astype(float)\n",
    "\n",
    "average_percentage_diff = df['Percentage Difference'].mean()\n",
    "print(f\"Accuracy: {accuracy:.3f} Average Percentage Difference: {average_percentage_diff:.3f}% for timeseries of {len(df)} datapoints across {len(cols_used)} features: {cols_used}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Open 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature High 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Low 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Close 491\n",
      "num_samples 524\n",
      "Target number of chunks to create an image for Feature Adj Close 491\n",
      "len images 5 len price list 5 len labels 491\n",
      "Shape of images before transpose: (5, 1, 491, 1, 32, 32)\n",
      "Shape of images after transpose: (1, 1, 5, 491, 32, 32)\n",
      "shape [0] set (1, 5, 491, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "cols_used = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]\n",
    "cols_used_count = sum(column_name in cols_used for column_name in dataset.columns)\n",
    "\n",
    "def generate_multiple_feature_images(dataset, image_size=32, method=\"summation\", sample_range = (0, 1)):\n",
    "    \n",
    "    feature_image_dataset_list=[[] for _ in range(len(cols_used))]\n",
    "    feature_price_dataset_list=[[] for _ in range(len(cols_used))] #=\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    feature_label_dataset_list=[] #next value for each chunk of =\"Open\", \"High\", \"Low\", \"Close\" , \"Adj Close\"\n",
    "    \n",
    "    column_idx = 0\n",
    "\n",
    "    for idx, column_name in enumerate(dataset.columns):\n",
    "\n",
    "      #create open, high, low and close images\n",
    "      if column_name in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"]:\n",
    "        temp_image_list = []\n",
    "        temp_price_list = []\n",
    "        #print(\"dataset idx\", idx, \"len rows this data feature\", len(dataset[i]), \"dataset[i].shape\", dataset[i].shape, \"dataset i:\", dataset[i])\n",
    "\n",
    "        feature_data = dataset[column_name].values\n",
    "        num_samples = len(feature_data)\n",
    "        print(\"num_samples\",num_samples)\n",
    "\n",
    "        #print(\"feature_dataset_array idx\", idx, \"len rows feature_dataset_array\", len(feature_dataset_array[0]), \"shape\",feature_dataset_array.shape, \"feature_dataset_array:\", feature_dataset_array)\n",
    "        \n",
    "        # generate_gaf_images generates images from full dataset according to image_size\n",
    "        # however, we loop by data_chunk so each chunk represents the price series that we slide by one day forward\n",
    "        # and generate an image for each slice\n",
    "        # TODO: parallelism\n",
    "        # we add cushion to slide the window forward\n",
    "        print(f\"Target number of chunks to create an image for Feature {column_name}\",num_samples - (image_size+1))\n",
    "        for cur_chunk in range(num_samples - (image_size+1)):\n",
    "          \n",
    "          #chunk size of image size\n",
    "          data_chunk = feature_data[cur_chunk:cur_chunk+image_size]\n",
    "          \n",
    "          #append gaf image to image list. store price feature values in price list\n",
    "          gaf_images, price_list = generate_gaf_images(data_chunk, gaf_img_sz=image_size, method=method, sample_range=sample_range)\n",
    "          temp_image_list.append(gaf_images)\n",
    "          \n",
    "          # if(cur_chunk==0):\n",
    "          #   print(\"Price Data Pre-Gaf: i\", cur_chunk, \"len\",len(data_chunk), \"shape\", feature_data.shape, \"data\",data_chunk)\n",
    "          #   print(\"Image Returned: idx\", idx, \"image size\", gaf_images.size, f\"first {image_size} image vals\", gaf_images.flatten()[:image_size])\n",
    "          \n",
    "          temp_price_list.append(price_list)\n",
    "          \n",
    "          #get next single value after the chunk as label to list\n",
    "          if(column_name == \"Open\"):\n",
    "            feature_label_dataset_list.append(cur_chunk + image_size + 1)\n",
    "        \n",
    "        feature_image_dataset_list[column_idx].append(temp_image_list)\n",
    "        feature_price_dataset_list[column_idx].append(price_list)\n",
    "        column_idx += 1\n",
    "\n",
    "\n",
    "    print(\"len images\",len(feature_image_dataset_list),\"len price list\",len(feature_price_dataset_list), \"len labels\", len(feature_label_dataset_list)) # 2455=total range*5\n",
    "    \n",
    "    feature_image_dataset_list = np.array(feature_image_dataset_list) \n",
    "    print(\"Shape of images before transpose:\", feature_image_dataset_list.shape)\n",
    "    \n",
    "    #transpose image for CNN\n",
    "    #(5, 1, 491, 1, 32, 32)\n",
    "    feature_image_dataset_list= np.transpose(feature_image_dataset_list, (1, 3, 0, 2, 4, 5))\n",
    "    print(\"Shape of images after transpose:\", feature_image_dataset_list.shape)\n",
    "\n",
    "    return feature_image_dataset_list, feature_price_dataset_list, feature_label_dataset_list\n",
    "\n",
    "#Generate images from dataset\n",
    "gaf_method=\"summation\"\n",
    "sample_range = (0, 1)\n",
    "image_size = 32 #(x,y)\n",
    "feature_image_dataset_list, feature_price_dataset_list, feature_label_dataset_list = generate_multiple_feature_images(dataset, image_size=image_size, method=gaf_method, sample_range=sample_range)\n",
    "\n",
    "print(\"shape [0] set\",np.array(feature_image_dataset_list[0]).shape)\n",
    "\n",
    "np.set_printoptions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization for CNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Optimization(output_conv_1, \n",
    "                     output_conv_2,\n",
    "                     dropout_probab,\n",
    "                     learning_rate,\n",
    "                     train_loader,test_loader):\n",
    "    \n",
    "    output_conv_1 = int(output_conv_1)\n",
    "    output_conv_2 = int(output_conv_2)\n",
    "    \n",
    "    net = Net(output_conv_1=output_conv_1, output_conv_2=output_conv_2,dropout_probab=dropout_probab)\n",
    "    net.to(device)\n",
    "\n",
    "    Train(learning_rate=learning_rate, train_loader=train_loader, net=net)\n",
    "\n",
    "    predicted,actual,accuracy = Test(test_loader=test_loader,net=net)\n",
    "    print(\"accuracy received\",accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial\n",
    "\n",
    "def Optimize():\n",
    "    \n",
    "    Generate_Train_And_Test_Loaders(feature_image_dataset_list_f32,labels_scaled_list_f32, train_shuffle=False, batch_size=10)\n",
    "    \n",
    "    cnn_correct_pct = partial(CNN_Optimization, train_loader = train_loader, test_loader = test_loader)\n",
    "\n",
    "    # Bounded region of parameter space\n",
    "    pbounds = {'output_conv_1': (40, 80), 'output_conv_2': (8, 16), 'learning_rate': (0.001, 0.01), 'dropout_probab': (0.0, 0.5)}\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=cnn_correct_pct,\n",
    "        pbounds=pbounds,\n",
    "        random_state=1,\n",
    "        )\n",
    "\n",
    "    #n_iter:steps of bayesian optimization you want to perform\n",
    "    #init_points:steps of random exploration\n",
    "    optimizer.maximize(init_points=10, n_iter=10,)\n",
    "\n",
    "    for i, res in enumerate(optimizer.res):\n",
    "        print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "    print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 491, 32, 32) 5\n",
      "input_shape torch.Size([10, 1, 32, 32]) label_shape torch.Size([10, 1])\n",
      "|   iter    |  target   | dropou... | learni... | output... | output... |\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "Convos & dropoutP: 40 10 0.208511002351287\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 10\n",
      "LeNet5Blend: total params: 63379\n",
      "Train params: 0.007482920440979424 0.9\n",
      "[1,    50] Cum loss: 0.383168\n",
      "[1,   100] Cum loss: 0.023615\n",
      "[1,   150] Cum loss: 0.019252\n",
      "[2,    50] Cum loss: 0.007042\n",
      "[2,   100] Cum loss: 0.005254\n",
      "[2,   150] Cum loss: 0.008708\n",
      "[3,    50] Cum loss: 0.004230\n",
      "[3,   100] Cum loss: 0.003883\n",
      "[3,   150] Cum loss: 0.003353\n",
      "[4,    50] Cum loss: 0.004754\n",
      "[4,   100] Cum loss: 0.001629\n",
      "[4,   150] Cum loss: 0.003406\n",
      "[5,    50] Cum loss: 0.003045\n",
      "[5,   100] Cum loss: 0.000960\n",
      "[5,   150] Cum loss: 0.001278\n",
      "[6,    50] Cum loss: 0.001115\n",
      "[6,   100] Cum loss: 0.003305\n",
      "[6,   150] Cum loss: 0.000928\n",
      "[7,    50] Cum loss: 0.000718\n",
      "[7,   100] Cum loss: 0.000939\n",
      "[7,   150] Cum loss: 0.003486\n",
      "[8,    50] Cum loss: 0.001539\n",
      "[8,   100] Cum loss: 0.001150\n",
      "[8,   150] Cum loss: 0.001155\n",
      "[9,    50] Cum loss: 0.000898\n",
      "[9,   100] Cum loss: 0.000916\n",
      "[9,   150] Cum loss: 0.002421\n",
      "[10,    50] Cum loss: 0.000991\n",
      "[10,   100] Cum loss: 0.000602\n",
      "[10,   150] Cum loss: 0.001070\n",
      "[11,    50] Cum loss: 0.000492\n",
      "[11,   100] Cum loss: 0.000720\n",
      "[11,   150] Cum loss: 0.000719\n",
      "[12,    50] Cum loss: 0.000817\n",
      "[12,   100] Cum loss: 0.000736\n",
      "[12,   150] Cum loss: 0.001597\n",
      "[13,    50] Cum loss: 0.000405\n",
      "[13,   100] Cum loss: 0.000797\n",
      "[13,   150] Cum loss: 0.000716\n",
      "[14,    50] Cum loss: 0.000606\n",
      "[14,   100] Cum loss: 0.000891\n",
      "[14,   150] Cum loss: 0.000330\n",
      "[15,    50] Cum loss: 0.000794\n",
      "[15,   100] Cum loss: 0.000287\n",
      "[15,   150] Cum loss: 0.000833\n",
      "[16,    50] Cum loss: 0.000215\n",
      "[16,   100] Cum loss: 0.000192\n",
      "[16,   150] Cum loss: 0.000226\n",
      "[17,    50] Cum loss: 0.000334\n",
      "[17,   100] Cum loss: 0.000777\n",
      "[17,   150] Cum loss: 0.000846\n",
      "[18,    50] Cum loss: 0.000365\n",
      "[18,   100] Cum loss: 0.000196\n",
      "[18,   150] Cum loss: 0.000550\n",
      "[19,    50] Cum loss: 0.000137\n",
      "[19,   100] Cum loss: 0.000228\n",
      "[19,   150] Cum loss: 0.000098\n",
      "[20,    50] Cum loss: 0.000104\n",
      "[20,   100] Cum loss: 0.000075\n",
      "[20,   150] Cum loss: 0.000085\n",
      "Percentage of predictions within 2 decimal places: 87.78%\n",
      "accuracy received 87.78004073319755\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m87.78    \u001b[0m | \u001b[0m0.2085   \u001b[0m | \u001b[0m0.007483 \u001b[0m | \u001b[0m40.0     \u001b[0m | \u001b[0m10.42    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 47 10 0.07337794540855652\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 10\n",
      "LeNet5Blend: total params: 63834\n",
      "Train params: 0.0018310473529191804 0.9\n",
      "[1,    50] Cum loss: 0.241099\n",
      "[1,   100] Cum loss: 0.024621\n",
      "[1,   150] Cum loss: 0.013026\n",
      "[2,    50] Cum loss: 0.004746\n",
      "[2,   100] Cum loss: 0.004324\n",
      "[2,   150] Cum loss: 0.007138\n",
      "[3,    50] Cum loss: 0.001808\n",
      "[3,   100] Cum loss: 0.001750\n",
      "[3,   150] Cum loss: 0.002229\n",
      "[4,    50] Cum loss: 0.001125\n",
      "[4,   100] Cum loss: 0.001686\n",
      "[4,   150] Cum loss: 0.001140\n",
      "[5,    50] Cum loss: 0.000754\n",
      "[5,   100] Cum loss: 0.001266\n",
      "[5,   150] Cum loss: 0.002749\n",
      "[6,    50] Cum loss: 0.000665\n",
      "[6,   100] Cum loss: 0.001475\n",
      "[6,   150] Cum loss: 0.001245\n",
      "[7,    50] Cum loss: 0.000705\n",
      "[7,   100] Cum loss: 0.000491\n",
      "[7,   150] Cum loss: 0.000529\n",
      "[8,    50] Cum loss: 0.001207\n",
      "[8,   100] Cum loss: 0.001344\n",
      "[8,   150] Cum loss: 0.000925\n",
      "[9,    50] Cum loss: 0.000569\n",
      "[9,   100] Cum loss: 0.000596\n",
      "[9,   150] Cum loss: 0.001200\n",
      "[10,    50] Cum loss: 0.000746\n",
      "[10,   100] Cum loss: 0.000770\n",
      "[10,   150] Cum loss: 0.000776\n",
      "[11,    50] Cum loss: 0.001191\n",
      "[11,   100] Cum loss: 0.000950\n",
      "[11,   150] Cum loss: 0.000868\n",
      "[12,    50] Cum loss: 0.000666\n",
      "[12,   100] Cum loss: 0.000345\n",
      "[12,   150] Cum loss: 0.000669\n",
      "[13,    50] Cum loss: 0.002698\n",
      "[13,   100] Cum loss: 0.001225\n",
      "[13,   150] Cum loss: 0.000398\n",
      "[14,    50] Cum loss: 0.000398\n",
      "[14,   100] Cum loss: 0.000762\n",
      "[14,   150] Cum loss: 0.000394\n",
      "[15,    50] Cum loss: 0.001137\n",
      "[15,   100] Cum loss: 0.001983\n",
      "[15,   150] Cum loss: 0.000543\n",
      "[16,    50] Cum loss: 0.000582\n",
      "[16,   100] Cum loss: 0.001016\n",
      "[16,   150] Cum loss: 0.000421\n",
      "[17,    50] Cum loss: 0.000944\n",
      "[17,   100] Cum loss: 0.000969\n",
      "[17,   150] Cum loss: 0.001602\n",
      "[18,    50] Cum loss: 0.000410\n",
      "[18,   100] Cum loss: 0.000801\n",
      "[18,   150] Cum loss: 0.000908\n",
      "[19,    50] Cum loss: 0.001051\n",
      "[19,   100] Cum loss: 0.000425\n",
      "[19,   150] Cum loss: 0.000503\n",
      "[20,    50] Cum loss: 0.000723\n",
      "[20,   100] Cum loss: 0.000273\n",
      "[20,   150] Cum loss: 0.000311\n",
      "Percentage of predictions within 2 decimal places: 23.83%\n",
      "accuracy received 23.828920570264767\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m23.83    \u001b[0m | \u001b[0m0.07338  \u001b[0m | \u001b[0m0.001831 \u001b[0m | \u001b[0m47.45    \u001b[0m | \u001b[0m10.76    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 56 13 0.19838373711533497\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 13\n",
      "LeNet5Blend: total params: 80550\n",
      "Train params: 0.005849350606030213 0.9\n",
      "[1,    50] Cum loss: 1.316554\n",
      "[1,   100] Cum loss: 0.009026\n",
      "Loss is less than 0.0001. Stopping training.\n",
      "Percentage of predictions within 2 decimal places: 0.00%\n",
      "accuracy received 0.0\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1984   \u001b[0m | \u001b[0m0.005849 \u001b[0m | \u001b[0m56.77    \u001b[0m | \u001b[0m13.48    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 41 13 0.10222612486575872\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 13\n",
      "LeNet5Blend: total params: 79305\n",
      "Train params: 0.00890305692751851 0.9\n",
      "[1,    50] Cum loss: 0.809577\n",
      "[1,   100] Cum loss: 0.002528\n",
      "Loss is less than 0.0001. Stopping training.\n",
      "Percentage of predictions within 2 decimal places: 100.00%\n",
      "accuracy received 100.0\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m100.0    \u001b[0m | \u001b[95m0.1022   \u001b[0m | \u001b[95m0.008903 \u001b[0m | \u001b[95m41.1     \u001b[0m | \u001b[95m13.36    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 45 9 0.20865240118356349\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 9\n",
      "LeNet5Blend: total params: 58393\n",
      "Train params: 0.006028208456011766 0.9\n",
      "[1,    50] Cum loss: 1.087702\n",
      "[1,   100] Cum loss: 0.018183\n",
      "[1,   150] Cum loss: 0.010078\n",
      "[2,    50] Cum loss: 0.003481\n",
      "[2,   100] Cum loss: 0.003700\n",
      "[2,   150] Cum loss: 0.004024\n",
      "[3,    50] Cum loss: 0.002538\n",
      "[3,   100] Cum loss: 0.001871\n",
      "[3,   150] Cum loss: 0.001577\n",
      "[4,    50] Cum loss: 0.002338\n",
      "[4,   100] Cum loss: 0.001421\n",
      "[4,   150] Cum loss: 0.001148\n",
      "[5,    50] Cum loss: 0.000928\n",
      "[5,   100] Cum loss: 0.000992\n",
      "[5,   150] Cum loss: 0.001055\n",
      "[6,    50] Cum loss: 0.001610\n",
      "[6,   100] Cum loss: 0.002245\n",
      "[6,   150] Cum loss: 0.000854\n",
      "[7,    50] Cum loss: 0.000637\n",
      "[7,   100] Cum loss: 0.000573\n",
      "[7,   150] Cum loss: 0.000570\n",
      "[8,    50] Cum loss: 0.000656\n",
      "[8,   100] Cum loss: 0.000317\n",
      "[8,   150] Cum loss: 0.000497\n",
      "[9,    50] Cum loss: 0.000883\n",
      "[9,   100] Cum loss: 0.000535\n",
      "[9,   150] Cum loss: 0.000655\n",
      "[10,    50] Cum loss: 0.000438\n",
      "[10,   100] Cum loss: 0.000429\n",
      "[10,   150] Cum loss: 0.000458\n",
      "[11,    50] Cum loss: 0.000871\n",
      "[11,   100] Cum loss: 0.001243\n",
      "[11,   150] Cum loss: 0.001337\n",
      "[12,    50] Cum loss: 0.000881\n",
      "[12,   100] Cum loss: 0.000600\n",
      "[12,   150] Cum loss: 0.000301\n",
      "[13,    50] Cum loss: 0.000804\n",
      "[13,   100] Cum loss: 0.000931\n",
      "[13,   150] Cum loss: 0.000228\n",
      "[14,    50] Cum loss: 0.000397\n",
      "[14,   100] Cum loss: 0.000845\n",
      "[14,   150] Cum loss: 0.000873\n",
      "[15,    50] Cum loss: 0.000204\n",
      "[15,   100] Cum loss: 0.000134\n",
      "[15,   150] Cum loss: 0.000313\n",
      "[16,    50] Cum loss: 0.000186\n",
      "[16,   100] Cum loss: 0.000297\n",
      "[16,   150] Cum loss: 0.000239\n",
      "[17,    50] Cum loss: 0.000277\n",
      "[17,   100] Cum loss: 0.000307\n",
      "[17,   150] Cum loss: 0.000371\n",
      "[18,    50] Cum loss: 0.000156\n",
      "[18,   100] Cum loss: 0.000115\n",
      "[18,   150] Cum loss: 0.000106\n",
      "[19,    50] Cum loss: 0.000138\n",
      "[19,   100] Cum loss: 0.000127\n",
      "[19,   150] Cum loss: 0.000117\n",
      "[20,    50] Cum loss: 0.000300\n",
      "[20,   100] Cum loss: 0.000146\n",
      "[20,   150] Cum loss: 0.000086\n",
      "Percentage of predictions within 2 decimal places: 45.21%\n",
      "accuracy received 45.21384928716905\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m45.21    \u001b[0m | \u001b[0m0.2087   \u001b[0m | \u001b[0m0.006028 \u001b[0m | \u001b[0m45.62    \u001b[0m | \u001b[0m9.585    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 52 13 0.40037228433776834\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 13\n",
      "LeNet5Blend: total params: 80218\n",
      "Train params: 0.00971435418147458 0.9\n",
      "[1,    50] Cum loss: 2.945639\n",
      "[1,   100] Cum loss: 0.027928\n",
      "[1,   150] Cum loss: 0.013881\n",
      "[2,    50] Cum loss: 0.007393\n",
      "[2,   100] Cum loss: 0.005553\n",
      "[2,   150] Cum loss: 0.003736\n",
      "[3,    50] Cum loss: 0.004688\n",
      "[3,   100] Cum loss: 0.002181\n",
      "[3,   150] Cum loss: 0.002833\n",
      "[4,    50] Cum loss: 0.004630\n",
      "[4,   100] Cum loss: 0.004887\n",
      "[4,   150] Cum loss: 0.001449\n",
      "[5,    50] Cum loss: 0.003992\n",
      "[5,   100] Cum loss: 0.001375\n",
      "[5,   150] Cum loss: 0.008749\n",
      "[6,    50] Cum loss: 0.001637\n",
      "[6,   100] Cum loss: 0.003913\n",
      "[6,   150] Cum loss: 0.006022\n",
      "[7,    50] Cum loss: 0.002702\n",
      "[7,   100] Cum loss: 0.001709\n",
      "[7,   150] Cum loss: 0.001030\n",
      "[8,    50] Cum loss: 0.003619\n",
      "[8,   100] Cum loss: 0.001815\n",
      "[8,   150] Cum loss: 0.001118\n",
      "[9,    50] Cum loss: 0.002202\n",
      "[9,   100] Cum loss: 0.002709\n",
      "[9,   150] Cum loss: 0.001878\n",
      "[10,    50] Cum loss: 0.001380\n",
      "[10,   100] Cum loss: 0.002383\n",
      "[10,   150] Cum loss: 0.001661\n",
      "[11,    50] Cum loss: 0.000740\n",
      "[11,   100] Cum loss: 0.001190\n",
      "[11,   150] Cum loss: 0.001250\n",
      "[12,    50] Cum loss: 0.173128\n",
      "[12,   100] Cum loss: 0.010215\n",
      "[12,   150] Cum loss: 0.001953\n",
      "[13,    50] Cum loss: 0.000872\n",
      "[13,   100] Cum loss: 0.000758\n",
      "[13,   150] Cum loss: 0.000585\n",
      "[14,    50] Cum loss: 0.000561\n",
      "[14,   100] Cum loss: 0.000455\n",
      "[14,   150] Cum loss: 0.000367\n",
      "[15,    50] Cum loss: 0.000584\n",
      "[15,   100] Cum loss: 0.000308\n",
      "[15,   150] Cum loss: 0.000218\n",
      "[16,    50] Cum loss: 0.000255\n",
      "[16,   100] Cum loss: 0.000194\n",
      "[16,   150] Cum loss: 0.000156\n",
      "[17,    50] Cum loss: 0.000265\n",
      "[17,   100] Cum loss: 0.000180\n",
      "[17,   150] Cum loss: 0.000186\n",
      "[18,    50] Cum loss: 0.000182\n",
      "[18,   100] Cum loss: 0.000187\n",
      "[18,   150] Cum loss: 0.000118\n",
      "[19,    50] Cum loss: 0.000179\n",
      "[19,   100] Cum loss: 0.000258\n",
      "[19,   150] Cum loss: 0.000127\n",
      "[20,    50] Cum loss: 0.000116\n",
      "[20,   100] Cum loss: 0.000137\n",
      "[20,   150] Cum loss: 0.000145\n",
      "Percentage of predictions within 2 decimal places: 72.30%\n",
      "accuracy received 72.30142566191446\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m72.3     \u001b[0m | \u001b[0m0.4004   \u001b[0m | \u001b[0m0.009714 \u001b[0m | \u001b[0m52.54    \u001b[0m | \u001b[0m13.54    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 43 8 0.43819457614801915\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 8\n",
      "LeNet5Blend: total params: 52976\n",
      "Train params: 0.009051459971534628 0.9\n",
      "[1,    50] Cum loss: 0.978053\n",
      "Loss is less than 0.0001. Stopping training.\n",
      "Percentage of predictions within 2 decimal places: 0.00%\n",
      "accuracy received 0.0\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.4382   \u001b[0m | \u001b[0m0.009051 \u001b[0m | \u001b[0m43.4     \u001b[0m | \u001b[0m8.312    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 43 11 0.08491520978228445\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 11\n",
      "LeNet5Blend: total params: 68873\n",
      "Train params: 0.008903282530864719 0.9\n",
      "[1,    50] Cum loss: 0.462295\n",
      "[1,   100] Cum loss: 0.026195\n",
      "[1,   150] Cum loss: 0.007637\n",
      "[2,    50] Cum loss: 0.004334\n",
      "[2,   100] Cum loss: 0.010183\n",
      "[2,   150] Cum loss: 0.007416\n",
      "[3,    50] Cum loss: 0.003689\n",
      "[3,   100] Cum loss: 0.001417\n",
      "[3,   150] Cum loss: 0.007140\n",
      "[4,    50] Cum loss: 0.003533\n",
      "[4,   100] Cum loss: 0.002038\n",
      "[4,   150] Cum loss: 0.005246\n",
      "[5,    50] Cum loss: 0.001390\n",
      "[5,   100] Cum loss: 0.002160\n",
      "[5,   150] Cum loss: 0.006166\n",
      "[6,    50] Cum loss: 0.001389\n",
      "[6,   100] Cum loss: 0.002899\n",
      "[6,   150] Cum loss: 0.001086\n",
      "[7,    50] Cum loss: 0.000452\n",
      "[7,   100] Cum loss: 0.000868\n",
      "[7,   150] Cum loss: 0.000934\n",
      "[8,    50] Cum loss: 0.001173\n",
      "[8,   100] Cum loss: 0.001542\n",
      "[8,   150] Cum loss: 0.000458\n",
      "[9,    50] Cum loss: 0.003851\n",
      "[9,   100] Cum loss: 0.000569\n",
      "[9,   150] Cum loss: 0.000910\n",
      "[10,    50] Cum loss: 0.014714\n",
      "[10,   100] Cum loss: 0.003934\n",
      "[10,   150] Cum loss: 0.001980\n",
      "[11,    50] Cum loss: 0.000529\n",
      "[11,   100] Cum loss: 0.000686\n",
      "[11,   150] Cum loss: 0.000681\n",
      "[12,    50] Cum loss: 0.000986\n",
      "[12,   100] Cum loss: 0.000332\n",
      "[12,   150] Cum loss: 0.000398\n",
      "[13,    50] Cum loss: 0.000209\n",
      "[13,   100] Cum loss: 0.000240\n",
      "[13,   150] Cum loss: 0.000605\n",
      "[14,    50] Cum loss: 0.001225\n",
      "[14,   100] Cum loss: 0.000486\n",
      "[14,   150] Cum loss: 0.000709\n",
      "[15,    50] Cum loss: 0.000833\n",
      "[15,   100] Cum loss: 0.008958\n",
      "[15,   150] Cum loss: 0.001199\n",
      "[16,    50] Cum loss: 0.000440\n",
      "[16,   100] Cum loss: 0.000495\n",
      "[16,   150] Cum loss: 0.000770\n",
      "[17,    50] Cum loss: 0.000418\n",
      "[17,   100] Cum loss: 0.000191\n",
      "[17,   150] Cum loss: 0.000295\n",
      "[18,    50] Cum loss: 0.000159\n",
      "[18,   100] Cum loss: 0.000173\n",
      "[18,   150] Cum loss: 0.000122\n",
      "[19,    50] Cum loss: 0.000281\n",
      "[19,   100] Cum loss: 0.001864\n",
      "[19,   150] Cum loss: 0.000491\n",
      "[20,    50] Cum loss: 0.000209\n",
      "[20,   100] Cum loss: 0.000114\n",
      "[20,   150] Cum loss: 0.000389\n",
      "Percentage of predictions within 2 decimal places: 78.41%\n",
      "accuracy received 78.41140529531569\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m78.41    \u001b[0m | \u001b[0m0.08492  \u001b[0m | \u001b[0m0.008903 \u001b[0m | \u001b[0m43.93    \u001b[0m | \u001b[0m11.37    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 67 10 0.47894476507525097\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 10\n",
      "LeNet5Blend: total params: 65134\n",
      "Train params: 0.005798487564757154 0.9\n",
      "[1,    50] Cum loss: 0.578353\n",
      "[1,   100] Cum loss: 0.034227\n",
      "[1,   150] Cum loss: 0.019469\n",
      "[2,    50] Cum loss: 0.008410\n",
      "[2,   100] Cum loss: 0.004978\n",
      "[2,   150] Cum loss: 0.003812\n",
      "[3,    50] Cum loss: 0.002145\n",
      "[3,   100] Cum loss: 0.002073\n",
      "[3,   150] Cum loss: 0.003235\n",
      "[4,    50] Cum loss: 0.002363\n",
      "[4,   100] Cum loss: 0.003144\n",
      "[4,   150] Cum loss: 0.001348\n",
      "[5,    50] Cum loss: 0.000726\n",
      "[5,   100] Cum loss: 0.001486\n",
      "[5,   150] Cum loss: 0.001253\n",
      "[6,    50] Cum loss: 0.000764\n",
      "[6,   100] Cum loss: 0.001667\n",
      "[6,   150] Cum loss: 0.001973\n",
      "[7,    50] Cum loss: 0.001451\n",
      "[7,   100] Cum loss: 0.000357\n",
      "[7,   150] Cum loss: 0.000614\n",
      "[8,    50] Cum loss: 0.000952\n",
      "[8,   100] Cum loss: 0.000766\n",
      "[8,   150] Cum loss: 0.000509\n",
      "[9,    50] Cum loss: 0.001242\n",
      "[9,   100] Cum loss: 0.000458\n",
      "[9,   150] Cum loss: 0.002038\n",
      "[10,    50] Cum loss: 0.000455\n",
      "[10,   100] Cum loss: 0.000414\n",
      "[10,   150] Cum loss: 0.000657\n",
      "[11,    50] Cum loss: 0.001113\n",
      "[11,   100] Cum loss: 0.000734\n",
      "[11,   150] Cum loss: 0.000545\n",
      "[12,    50] Cum loss: 0.001430\n",
      "[12,   100] Cum loss: 0.001456\n",
      "[12,   150] Cum loss: 0.000691\n",
      "[13,    50] Cum loss: 0.001147\n",
      "[13,   100] Cum loss: 0.001021\n",
      "[13,   150] Cum loss: 0.000814\n",
      "[14,    50] Cum loss: 0.000558\n",
      "[14,   100] Cum loss: 0.000347\n",
      "[14,   150] Cum loss: 0.000431\n",
      "[15,    50] Cum loss: 0.001104\n",
      "[15,   100] Cum loss: 0.000745\n",
      "[15,   150] Cum loss: 0.001693\n",
      "[16,    50] Cum loss: 0.000436\n",
      "[16,   100] Cum loss: 0.000410\n",
      "[16,   150] Cum loss: 0.000696\n",
      "[17,    50] Cum loss: 0.000307\n",
      "[17,   100] Cum loss: 0.000648\n",
      "[17,   150] Cum loss: 0.000277\n",
      "[18,    50] Cum loss: 0.000307\n",
      "[18,   100] Cum loss: 0.000413\n",
      "[18,   150] Cum loss: 0.000337\n",
      "[19,    50] Cum loss: 0.000448\n",
      "[19,   100] Cum loss: 0.000365\n",
      "[19,   150] Cum loss: 0.000082\n",
      "[20,    50] Cum loss: 0.000969\n",
      "[20,   100] Cum loss: 0.002458\n",
      "[20,   150] Cum loss: 0.000149\n",
      "Percentage of predictions within 2 decimal places: 91.85%\n",
      "accuracy received 91.85336048879837\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m91.85    \u001b[0m | \u001b[0m0.4789   \u001b[0m | \u001b[0m0.005798 \u001b[0m | \u001b[0m67.68    \u001b[0m | \u001b[0m10.52    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 40 14 0.34325046384079183\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 14\n",
      "LeNet5Blend: total params: 84503\n",
      "Train params: 0.008511631047076357 0.9\n",
      "[1,    50] Cum loss: 0.957775\n",
      "[1,   100] Cum loss: 0.019273\n",
      "[1,   150] Cum loss: 0.008574\n",
      "[2,    50] Cum loss: 0.005174\n",
      "[2,   100] Cum loss: 0.002318\n",
      "[2,   150] Cum loss: 0.002957\n",
      "[3,    50] Cum loss: 0.001706\n",
      "[3,   100] Cum loss: 0.001062\n",
      "[3,   150] Cum loss: 0.002310\n",
      "[4,    50] Cum loss: 0.001454\n",
      "[4,   100] Cum loss: 0.001516\n",
      "[4,   150] Cum loss: 0.000995\n",
      "[5,    50] Cum loss: 0.000744\n",
      "[5,   100] Cum loss: 0.000776\n",
      "[5,   150] Cum loss: 0.000717\n",
      "[6,    50] Cum loss: 0.000622\n",
      "[6,   100] Cum loss: 0.001265\n",
      "[6,   150] Cum loss: 0.000450\n",
      "[7,    50] Cum loss: 0.000294\n",
      "[7,   100] Cum loss: 0.000599\n",
      "[7,   150] Cum loss: 0.002027\n",
      "[8,    50] Cum loss: 0.000588\n",
      "[8,   100] Cum loss: 0.000351\n",
      "[8,   150] Cum loss: 0.002179\n",
      "[9,    50] Cum loss: 0.000421\n",
      "[9,   100] Cum loss: 0.000840\n",
      "[9,   150] Cum loss: 0.001057\n",
      "[10,    50] Cum loss: 0.004293\n",
      "[10,   100] Cum loss: 0.004464\n",
      "[10,   150] Cum loss: 0.000631\n",
      "[11,    50] Cum loss: 0.000359\n",
      "[11,   100] Cum loss: 0.001153\n",
      "[11,   150] Cum loss: 0.000349\n",
      "[12,    50] Cum loss: 0.000141\n",
      "[12,   100] Cum loss: 0.000560\n",
      "[12,   150] Cum loss: 0.000389\n",
      "[13,    50] Cum loss: 0.000548\n",
      "[13,   100] Cum loss: 0.000348\n",
      "[13,   150] Cum loss: 0.000178\n",
      "[14,    50] Cum loss: 0.000410\n",
      "[14,   100] Cum loss: 0.000587\n",
      "[14,   150] Cum loss: 0.004618\n",
      "[15,    50] Cum loss: 0.000270\n",
      "[15,   100] Cum loss: 0.000127\n",
      "[15,   150] Cum loss: 0.000100\n",
      "[16,    50] Cum loss: 0.000240\n",
      "[16,   100] Cum loss: 0.000123\n",
      "[16,   150] Cum loss: 0.000109\n",
      "[17,    50] Cum loss: 0.000046\n",
      "[17,   100] Cum loss: 0.000106\n",
      "[17,   150] Cum loss: 0.000067\n",
      "[18,    50] Cum loss: 0.000134\n",
      "[18,   100] Cum loss: 0.000121\n",
      "[18,   150] Cum loss: 0.000149\n",
      "[19,    50] Cum loss: 0.000181\n",
      "[19,   100] Cum loss: 0.000082\n",
      "[19,   150] Cum loss: 0.000118\n",
      "[20,    50] Cum loss: 0.000120\n",
      "[20,   100] Cum loss: 0.000248\n",
      "[20,   150] Cum loss: 0.000339\n",
      "Percentage of predictions within 2 decimal places: 0.00%\n",
      "accuracy received 0.0\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.3433   \u001b[0m | \u001b[0m0.008512 \u001b[0m | \u001b[0m40.73    \u001b[0m | \u001b[0m14.0     \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 43 11 0.10263124770225562\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 11\n",
      "LeNet5Blend: total params: 68873\n",
      "Train params: 0.00595281535168478 0.9\n",
      "[1,    50] Cum loss: 0.457993\n",
      "[1,   100] Cum loss: 0.023240\n",
      "[1,   150] Cum loss: 0.013684\n",
      "[2,    50] Cum loss: 0.014818\n",
      "[2,   100] Cum loss: 0.008776\n",
      "[2,   150] Cum loss: 0.006949\n",
      "[3,    50] Cum loss: 0.003025\n",
      "[3,   100] Cum loss: 0.004634\n",
      "[3,   150] Cum loss: 0.005857\n",
      "[4,    50] Cum loss: 0.002226\n",
      "[4,   100] Cum loss: 0.001164\n",
      "[4,   150] Cum loss: 0.002642\n",
      "[5,    50] Cum loss: 0.001229\n",
      "[5,   100] Cum loss: 0.002435\n",
      "[5,   150] Cum loss: 0.002577\n",
      "[6,    50] Cum loss: 0.004682\n",
      "[6,   100] Cum loss: 0.000725\n",
      "[6,   150] Cum loss: 0.001558\n",
      "[7,    50] Cum loss: 0.001233\n",
      "[7,   100] Cum loss: 0.000813\n",
      "[7,   150] Cum loss: 0.001525\n",
      "[8,    50] Cum loss: 0.001895\n",
      "[8,   100] Cum loss: 0.000680\n",
      "[8,   150] Cum loss: 0.000625\n",
      "[9,    50] Cum loss: 0.002325\n",
      "[9,   100] Cum loss: 0.001495\n",
      "[9,   150] Cum loss: 0.001474\n",
      "[10,    50] Cum loss: 0.001204\n",
      "[10,   100] Cum loss: 0.000867\n",
      "[10,   150] Cum loss: 0.001002\n",
      "[11,    50] Cum loss: 0.000714\n",
      "[11,   100] Cum loss: 0.006941\n",
      "[11,   150] Cum loss: 0.001435\n",
      "[12,    50] Cum loss: 0.000989\n",
      "[12,   100] Cum loss: 0.000691\n",
      "[12,   150] Cum loss: 0.000384\n",
      "[13,    50] Cum loss: 0.000511\n",
      "[13,   100] Cum loss: 0.001092\n",
      "[13,   150] Cum loss: 0.001299\n",
      "[14,    50] Cum loss: 0.000446\n",
      "[14,   100] Cum loss: 0.000323\n",
      "[14,   150] Cum loss: 0.005017\n",
      "[15,    50] Cum loss: 0.001281\n",
      "[15,   100] Cum loss: 0.000358\n",
      "[15,   150] Cum loss: 0.000296\n",
      "[16,    50] Cum loss: 0.000222\n",
      "[16,   100] Cum loss: 0.000276\n",
      "[16,   150] Cum loss: 0.000375\n",
      "[17,    50] Cum loss: 0.000291\n",
      "[17,   100] Cum loss: 0.000371\n",
      "[17,   150] Cum loss: 0.000355\n",
      "[18,    50] Cum loss: 0.001016\n",
      "[18,   100] Cum loss: 0.001136\n",
      "[18,   150] Cum loss: 0.001033\n",
      "[19,    50] Cum loss: 0.003845\n",
      "[19,   100] Cum loss: 0.001048\n",
      "[19,   150] Cum loss: 0.000595\n",
      "[20,    50] Cum loss: 0.000438\n",
      "[20,   100] Cum loss: 0.000613\n",
      "[20,   150] Cum loss: 0.000262\n",
      "Percentage of predictions within 2 decimal places: 31.77%\n",
      "accuracy received 31.771894093686353\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m31.77    \u001b[0m | \u001b[0m0.1026   \u001b[0m | \u001b[0m0.005953 \u001b[0m | \u001b[0m43.94    \u001b[0m | \u001b[0m11.41    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 61 13 0.22127865872773117\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 13\n",
      "LeNet5Blend: total params: 80965\n",
      "Train params: 0.004721236371406603 0.9\n",
      "[1,    50] Cum loss: 0.828566\n",
      "[1,   100] Cum loss: 0.027581\n",
      "[1,   150] Cum loss: 0.021799\n",
      "[2,    50] Cum loss: 0.008019\n",
      "[2,   100] Cum loss: 0.004720\n",
      "[2,   150] Cum loss: 0.004219\n",
      "[3,    50] Cum loss: 0.001469\n",
      "[3,   100] Cum loss: 0.002053\n",
      "[3,   150] Cum loss: 0.001708\n",
      "[4,    50] Cum loss: 0.001027\n",
      "[4,   100] Cum loss: 0.002051\n",
      "[4,   150] Cum loss: 0.003226\n",
      "[5,    50] Cum loss: 0.000816\n",
      "[5,   100] Cum loss: 0.001259\n",
      "[5,   150] Cum loss: 0.001104\n",
      "[6,    50] Cum loss: 0.000559\n",
      "[6,   100] Cum loss: 0.000925\n",
      "[6,   150] Cum loss: 0.000559\n",
      "[7,    50] Cum loss: 0.000563\n",
      "[7,   100] Cum loss: 0.000503\n",
      "[7,   150] Cum loss: 0.000365\n",
      "[8,    50] Cum loss: 0.002767\n",
      "[8,   100] Cum loss: 0.000760\n",
      "[8,   150] Cum loss: 0.000929\n",
      "[9,    50] Cum loss: 0.000774\n",
      "[9,   100] Cum loss: 0.000550\n",
      "[9,   150] Cum loss: 0.000451\n",
      "[10,    50] Cum loss: 0.000286\n",
      "[10,   100] Cum loss: 0.000473\n",
      "[10,   150] Cum loss: 0.000328\n",
      "[11,    50] Cum loss: 0.000593\n",
      "[11,   100] Cum loss: 0.000421\n",
      "[11,   150] Cum loss: 0.001664\n",
      "[12,    50] Cum loss: 0.001740\n",
      "[12,   100] Cum loss: 0.000760\n",
      "[12,   150] Cum loss: 0.000943\n",
      "[13,    50] Cum loss: 0.000720\n",
      "[13,   100] Cum loss: 0.000864\n",
      "[13,   150] Cum loss: 0.000690\n",
      "[14,    50] Cum loss: 0.000513\n",
      "[14,   100] Cum loss: 0.000196\n",
      "[14,   150] Cum loss: 0.000496\n",
      "[15,    50] Cum loss: 0.000440\n",
      "[15,   100] Cum loss: 0.000628\n",
      "[15,   150] Cum loss: 0.000391\n",
      "[16,    50] Cum loss: 0.000780\n",
      "[16,   100] Cum loss: 0.013002\n",
      "[16,   150] Cum loss: 0.003485\n",
      "[17,    50] Cum loss: 0.000359\n",
      "[17,   100] Cum loss: 0.000288\n",
      "[17,   150] Cum loss: 0.000796\n",
      "[18,    50] Cum loss: 0.000249\n",
      "[18,   100] Cum loss: 0.000297\n",
      "[18,   150] Cum loss: 0.000237\n",
      "[19,    50] Cum loss: 0.000134\n",
      "[19,   100] Cum loss: 0.000333\n",
      "[19,   150] Cum loss: 0.000359\n",
      "[20,    50] Cum loss: 0.000237\n",
      "[20,   100] Cum loss: 0.000387\n",
      "[20,   150] Cum loss: 0.000711\n",
      "Percentage of predictions within 2 decimal places: 69.25%\n",
      "accuracy received 69.24643584521385\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m69.25    \u001b[0m | \u001b[0m0.2213   \u001b[0m | \u001b[0m0.004721 \u001b[0m | \u001b[0m61.91    \u001b[0m | \u001b[0m13.95    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 78 14 0.31169284313929374\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 14\n",
      "LeNet5Blend: total params: 87885\n",
      "Train params: 0.0030090208294123733 0.9\n",
      "[1,    50] Cum loss: 0.705123\n",
      "[1,   100] Cum loss: 0.040025\n",
      "[1,   150] Cum loss: 0.026048\n",
      "[2,    50] Cum loss: 0.014194\n",
      "[2,   100] Cum loss: 0.006509\n",
      "[2,   150] Cum loss: 0.004450\n",
      "[3,    50] Cum loss: 0.002816\n",
      "[3,   100] Cum loss: 0.002587\n",
      "[3,   150] Cum loss: 0.001544\n",
      "[4,    50] Cum loss: 0.002909\n",
      "[4,   100] Cum loss: 0.001314\n",
      "[4,   150] Cum loss: 0.000978\n",
      "[5,    50] Cum loss: 0.000923\n",
      "[5,   100] Cum loss: 0.000737\n",
      "[5,   150] Cum loss: 0.000718\n",
      "[6,    50] Cum loss: 0.000547\n",
      "[6,   100] Cum loss: 0.000574\n",
      "[6,   150] Cum loss: 0.000569\n",
      "[7,    50] Cum loss: 0.000654\n",
      "[7,   100] Cum loss: 0.001392\n",
      "[7,   150] Cum loss: 0.000716\n",
      "[8,    50] Cum loss: 0.000743\n",
      "[8,   100] Cum loss: 0.001558\n",
      "[8,   150] Cum loss: 0.000327\n",
      "[9,    50] Cum loss: 0.000516\n",
      "[9,   100] Cum loss: 0.000605\n",
      "[9,   150] Cum loss: 0.000922\n",
      "[10,    50] Cum loss: 0.000302\n",
      "[10,   100] Cum loss: 0.000573\n",
      "[10,   150] Cum loss: 0.000722\n",
      "[11,    50] Cum loss: 0.000520\n",
      "[11,   100] Cum loss: 0.000512\n",
      "[11,   150] Cum loss: 0.000420\n",
      "[12,    50] Cum loss: 0.000543\n",
      "[12,   100] Cum loss: 0.001133\n",
      "[12,   150] Cum loss: 0.000933\n",
      "[13,    50] Cum loss: 0.000646\n",
      "[13,   100] Cum loss: 0.001367\n",
      "[13,   150] Cum loss: 0.001593\n",
      "[14,    50] Cum loss: 0.000422\n",
      "[14,   100] Cum loss: 0.000693\n",
      "[14,   150] Cum loss: 0.000796\n",
      "[15,    50] Cum loss: 0.000526\n",
      "[15,   100] Cum loss: 0.000730\n",
      "[15,   150] Cum loss: 0.001544\n",
      "[16,    50] Cum loss: 0.000893\n",
      "[16,   100] Cum loss: 0.001852\n",
      "[16,   150] Cum loss: 0.000515\n",
      "[17,    50] Cum loss: 0.000414\n",
      "[17,   100] Cum loss: 0.000340\n",
      "[17,   150] Cum loss: 0.000997\n",
      "[18,    50] Cum loss: 0.000708\n",
      "[18,   100] Cum loss: 0.000592\n",
      "[18,   150] Cum loss: 0.000732\n",
      "[19,    50] Cum loss: 0.000797\n",
      "[19,   100] Cum loss: 0.001146\n",
      "[19,   150] Cum loss: 0.001781\n",
      "[20,    50] Cum loss: 0.001599\n",
      "[20,   100] Cum loss: 0.000398\n",
      "[20,   150] Cum loss: 0.000444\n",
      "Percentage of predictions within 2 decimal places: 41.75%\n",
      "accuracy received 41.75152749490835\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m41.75    \u001b[0m | \u001b[0m0.3117   \u001b[0m | \u001b[0m0.003009 \u001b[0m | \u001b[0m78.36    \u001b[0m | \u001b[0m14.44    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 78 13 0.010603136826314419\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 13\n",
      "LeNet5Blend: total params: 82376\n",
      "Train params: 0.008270931156640491 0.9\n",
      "[1,    50] Cum loss: 2.246894\n",
      "[1,   100] Cum loss: 0.004837\n",
      "Loss is less than 0.0001. Stopping training.\n",
      "Percentage of predictions within 2 decimal places: 0.00%\n",
      "accuracy received 0.0\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.0106   \u001b[0m | \u001b[0m0.008271 \u001b[0m | \u001b[0m78.59    \u001b[0m | \u001b[0m13.62    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 46 15 0.18220959578371426\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 15\n",
      "LeNet5Blend: total params: 90354\n",
      "Train params: 0.0012015830002020354 0.9\n",
      "[1,    50] Cum loss: 0.232220\n",
      "[1,   100] Cum loss: 0.023833\n",
      "[1,   150] Cum loss: 0.011004\n",
      "[2,    50] Cum loss: 0.006283\n",
      "[2,   100] Cum loss: 0.002969\n",
      "[2,   150] Cum loss: 0.002141\n",
      "[3,    50] Cum loss: 0.003198\n",
      "[3,   100] Cum loss: 0.001779\n",
      "[3,   150] Cum loss: 0.002232\n",
      "[4,    50] Cum loss: 0.002795\n",
      "[4,   100] Cum loss: 0.003139\n",
      "[4,   150] Cum loss: 0.001418\n",
      "[5,    50] Cum loss: 0.001715\n",
      "[5,   100] Cum loss: 0.001883\n",
      "[5,   150] Cum loss: 0.002525\n",
      "[6,    50] Cum loss: 0.001934\n",
      "[6,   100] Cum loss: 0.001524\n",
      "[6,   150] Cum loss: 0.001548\n",
      "[7,    50] Cum loss: 0.001462\n",
      "[7,   100] Cum loss: 0.000931\n",
      "[7,   150] Cum loss: 0.000776\n",
      "[8,    50] Cum loss: 0.001230\n",
      "[8,   100] Cum loss: 0.002718\n",
      "[8,   150] Cum loss: 0.000906\n",
      "[9,    50] Cum loss: 0.001021\n",
      "[9,   100] Cum loss: 0.000907\n",
      "[9,   150] Cum loss: 0.000970\n",
      "[10,    50] Cum loss: 0.001516\n",
      "[10,   100] Cum loss: 0.001203\n",
      "[10,   150] Cum loss: 0.001568\n",
      "[11,    50] Cum loss: 0.001040\n",
      "[11,   100] Cum loss: 0.002214\n",
      "[11,   150] Cum loss: 0.001723\n",
      "[12,    50] Cum loss: 0.000600\n",
      "[12,   100] Cum loss: 0.000623\n",
      "[12,   150] Cum loss: 0.001225\n",
      "[13,    50] Cum loss: 0.000771\n",
      "[13,   100] Cum loss: 0.001154\n",
      "[13,   150] Cum loss: 0.000731\n",
      "[14,    50] Cum loss: 0.000720\n",
      "[14,   100] Cum loss: 0.000528\n",
      "[14,   150] Cum loss: 0.001034\n",
      "[15,    50] Cum loss: 0.000840\n",
      "[15,   100] Cum loss: 0.000610\n",
      "[15,   150] Cum loss: 0.001266\n",
      "[16,    50] Cum loss: 0.000792\n",
      "[16,   100] Cum loss: 0.002195\n",
      "[16,   150] Cum loss: 0.001482\n",
      "[17,    50] Cum loss: 0.000524\n",
      "[17,   100] Cum loss: 0.000762\n",
      "[17,   150] Cum loss: 0.000478\n",
      "[18,    50] Cum loss: 0.001890\n",
      "[18,   100] Cum loss: 0.001280\n",
      "[18,   150] Cum loss: 0.000583\n",
      "[19,    50] Cum loss: 0.000815\n",
      "[19,   100] Cum loss: 0.000759\n",
      "[19,   150] Cum loss: 0.000522\n",
      "[20,    50] Cum loss: 0.000560\n",
      "[20,   100] Cum loss: 0.000636\n",
      "[20,   150] Cum loss: 0.000491\n",
      "Percentage of predictions within 2 decimal places: 32.99%\n",
      "accuracy received 32.9938900203666\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m32.99    \u001b[0m | \u001b[0m0.1822   \u001b[0m | \u001b[0m0.001202 \u001b[0m | \u001b[0m46.1     \u001b[0m | \u001b[0m15.77    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 72 8 0.497650103984265\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 8\n",
      "LeNet5Blend: total params: 54513\n",
      "Train params: 0.003926552552944402 0.9\n",
      "[1,    50] Cum loss: 0.147906\n",
      "[1,   100] Cum loss: 0.023459\n",
      "[1,   150] Cum loss: 0.011904\n",
      "[2,    50] Cum loss: 0.004154\n",
      "[2,   100] Cum loss: 0.002538\n",
      "[2,   150] Cum loss: 0.002322\n",
      "[3,    50] Cum loss: 0.002617\n",
      "[3,   100] Cum loss: 0.003199\n",
      "[3,   150] Cum loss: 0.001336\n",
      "[4,    50] Cum loss: 0.000540\n",
      "[4,   100] Cum loss: 0.000405\n",
      "[4,   150] Cum loss: 0.001013\n",
      "[5,    50] Cum loss: 0.000659\n",
      "[5,   100] Cum loss: 0.000551\n",
      "[5,   150] Cum loss: 0.001608\n",
      "[6,    50] Cum loss: 0.000436\n",
      "[6,   100] Cum loss: 0.000783\n",
      "[6,   150] Cum loss: 0.000490\n",
      "[7,    50] Cum loss: 0.001834\n",
      "[7,   100] Cum loss: 0.000454\n",
      "[7,   150] Cum loss: 0.000481\n",
      "[8,    50] Cum loss: 0.000544\n",
      "[8,   100] Cum loss: 0.000412\n",
      "[8,   150] Cum loss: 0.000537\n",
      "[9,    50] Cum loss: 0.000290\n",
      "[9,   100] Cum loss: 0.001089\n",
      "[9,   150] Cum loss: 0.002097\n",
      "[10,    50] Cum loss: 0.001226\n",
      "[10,   100] Cum loss: 0.001516\n",
      "[10,   150] Cum loss: 0.002488\n",
      "[11,    50] Cum loss: 0.000824\n",
      "[11,   100] Cum loss: 0.000351\n",
      "[11,   150] Cum loss: 0.000239\n",
      "[12,    50] Cum loss: 0.000263\n",
      "[12,   100] Cum loss: 0.000260\n",
      "[12,   150] Cum loss: 0.000167\n",
      "[13,    50] Cum loss: 0.000847\n",
      "[13,   100] Cum loss: 0.000465\n",
      "[13,   150] Cum loss: 0.001092\n",
      "[14,    50] Cum loss: 0.001045\n",
      "[14,   100] Cum loss: 0.000445\n",
      "[14,   150] Cum loss: 0.000676\n",
      "[15,    50] Cum loss: 0.000236\n",
      "[15,   100] Cum loss: 0.000462\n",
      "[15,   150] Cum loss: 0.000383\n",
      "[16,    50] Cum loss: 0.000545\n",
      "[16,   100] Cum loss: 0.000392\n",
      "[16,   150] Cum loss: 0.000110\n",
      "[17,    50] Cum loss: 0.002218\n",
      "[17,   100] Cum loss: 0.002657\n",
      "[17,   150] Cum loss: 0.000444\n",
      "[18,    50] Cum loss: 0.000396\n",
      "[18,   100] Cum loss: 0.000134\n",
      "[18,   150] Cum loss: 0.000532\n",
      "[19,    50] Cum loss: 0.000245\n",
      "[19,   100] Cum loss: 0.000204\n",
      "[19,   150] Cum loss: 0.000503\n",
      "[20,    50] Cum loss: 0.000142\n",
      "[20,   100] Cum loss: 0.000160\n",
      "[20,   150] Cum loss: 0.000132\n",
      "Percentage of predictions within 2 decimal places: 45.62%\n",
      "accuracy received 45.621181262729124\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m45.62    \u001b[0m | \u001b[0m0.4977   \u001b[0m | \u001b[0m0.003927 \u001b[0m | \u001b[0m72.67    \u001b[0m | \u001b[0m8.357    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 72 11 0.4906156469892826\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 11\n",
      "LeNet5Blend: total params: 70932\n",
      "Train params: 0.0034337559563296506 0.9\n",
      "[1,    50] Cum loss: 0.231461\n",
      "[1,   100] Cum loss: 0.012335\n",
      "[1,   150] Cum loss: 0.008448\n",
      "[2,    50] Cum loss: 0.003322\n",
      "[2,   100] Cum loss: 0.002530\n",
      "[2,   150] Cum loss: 0.001753\n",
      "[3,    50] Cum loss: 0.001041\n",
      "[3,   100] Cum loss: 0.002724\n",
      "[3,   150] Cum loss: 0.000932\n",
      "[4,    50] Cum loss: 0.001218\n",
      "[4,   100] Cum loss: 0.001160\n",
      "[4,   150] Cum loss: 0.001297\n",
      "[5,    50] Cum loss: 0.001213\n",
      "[5,   100] Cum loss: 0.001302\n",
      "[5,   150] Cum loss: 0.001284\n",
      "[6,    50] Cum loss: 0.000802\n",
      "[6,   100] Cum loss: 0.000635\n",
      "[6,   150] Cum loss: 0.000800\n",
      "[7,    50] Cum loss: 0.001205\n",
      "[7,   100] Cum loss: 0.001119\n",
      "[7,   150] Cum loss: 0.002195\n",
      "[8,    50] Cum loss: 0.002216\n",
      "[8,   100] Cum loss: 0.001943\n",
      "[8,   150] Cum loss: 0.001489\n",
      "[9,    50] Cum loss: 0.000308\n",
      "[9,   100] Cum loss: 0.000741\n",
      "[9,   150] Cum loss: 0.001599\n",
      "[10,    50] Cum loss: 0.001508\n",
      "[10,   100] Cum loss: 0.000762\n",
      "[10,   150] Cum loss: 0.002332\n",
      "[11,    50] Cum loss: 0.000568\n",
      "[11,   100] Cum loss: 0.000998\n",
      "[11,   150] Cum loss: 0.000618\n",
      "[12,    50] Cum loss: 0.000933\n",
      "[12,   100] Cum loss: 0.000557\n",
      "[12,   150] Cum loss: 0.000833\n",
      "[13,    50] Cum loss: 0.001008\n",
      "[13,   100] Cum loss: 0.000580\n",
      "[13,   150] Cum loss: 0.000262\n",
      "[14,    50] Cum loss: 0.000378\n",
      "[14,   100] Cum loss: 0.000598\n",
      "[14,   150] Cum loss: 0.000219\n",
      "[15,    50] Cum loss: 0.000239\n",
      "[15,   100] Cum loss: 0.000498\n",
      "[15,   150] Cum loss: 0.001353\n",
      "[16,    50] Cum loss: 0.000603\n",
      "[16,   100] Cum loss: 0.001000\n",
      "[16,   150] Cum loss: 0.001541\n",
      "[17,    50] Cum loss: 0.000270\n",
      "[17,   100] Cum loss: 0.000819\n",
      "[17,   150] Cum loss: 0.001577\n",
      "[18,    50] Cum loss: 0.000574\n",
      "[18,   100] Cum loss: 0.000817\n",
      "[18,   150] Cum loss: 0.000410\n",
      "[19,    50] Cum loss: 0.000495\n",
      "[19,   100] Cum loss: 0.000628\n",
      "[19,   150] Cum loss: 0.001177\n",
      "[20,    50] Cum loss: 0.000466\n",
      "[20,   100] Cum loss: 0.000551\n",
      "[20,   150] Cum loss: 0.000674\n",
      "Percentage of predictions within 2 decimal places: 43.79%\n",
      "accuracy received 43.78818737270876\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m43.79    \u001b[0m | \u001b[0m0.4906   \u001b[0m | \u001b[0m0.003434 \u001b[0m | \u001b[0m72.35    \u001b[0m | \u001b[0m11.57    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 56 14 0.162437880699506\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 14\n",
      "LeNet5Blend: total params: 85927\n",
      "Train params: 0.006722032745672147 0.9\n",
      "[1,    50] Cum loss: 1.970801\n",
      "Loss is less than 0.0001. Stopping training.\n",
      "Percentage of predictions within 2 decimal places: 0.00%\n",
      "accuracy received 0.0\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m0.1624   \u001b[0m | \u001b[0m0.006722 \u001b[0m | \u001b[0m56.02    \u001b[0m | \u001b[0m14.01    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 62 10 0.15295561033522215\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 10\n",
      "LeNet5Blend: total params: 64809\n",
      "Train params: 0.007089879736117241 0.9\n",
      "[1,    50] Cum loss: 0.830807\n",
      "[1,   100] Cum loss: 0.018726\n",
      "[1,   150] Cum loss: 0.021422\n",
      "[2,    50] Cum loss: 0.006389\n",
      "[2,   100] Cum loss: 0.003077\n",
      "[2,   150] Cum loss: 0.002915\n",
      "[3,    50] Cum loss: 0.001303\n",
      "[3,   100] Cum loss: 0.000918\n",
      "[3,   150] Cum loss: 0.000793\n",
      "[4,    50] Cum loss: 0.000990\n",
      "[4,   100] Cum loss: 0.000877\n",
      "[4,   150] Cum loss: 0.000639\n",
      "[5,    50] Cum loss: 0.000672\n",
      "[5,   100] Cum loss: 0.000539\n",
      "[5,   150] Cum loss: 0.000817\n",
      "[6,    50] Cum loss: 0.000324\n",
      "[6,   100] Cum loss: 0.000307\n",
      "[6,   150] Cum loss: 0.000399\n",
      "[7,    50] Cum loss: 0.000491\n",
      "[7,   100] Cum loss: 0.000511\n",
      "[7,   150] Cum loss: 0.000308\n",
      "[8,    50] Cum loss: 0.000245\n",
      "[8,   100] Cum loss: 0.000735\n",
      "[8,   150] Cum loss: 0.000338\n",
      "[9,    50] Cum loss: 0.000425\n",
      "[9,   100] Cum loss: 0.000453\n",
      "[9,   150] Cum loss: 0.000738\n",
      "[10,    50] Cum loss: 0.000653\n",
      "[10,   100] Cum loss: 0.001203\n",
      "[10,   150] Cum loss: 0.002416\n",
      "[11,    50] Cum loss: 0.000469\n",
      "[11,   100] Cum loss: 0.000355\n",
      "[11,   150] Cum loss: 0.000618\n",
      "[12,    50] Cum loss: 0.001093\n",
      "[12,   100] Cum loss: 0.000405\n",
      "[12,   150] Cum loss: 0.000343\n",
      "[13,    50] Cum loss: 0.007267\n",
      "[13,   100] Cum loss: 0.001158\n",
      "[13,   150] Cum loss: 0.001115\n",
      "[14,    50] Cum loss: 0.000499\n",
      "[14,   100] Cum loss: 0.000139\n",
      "[14,   150] Cum loss: 0.000232\n",
      "[15,    50] Cum loss: 0.000642\n",
      "[15,   100] Cum loss: 0.000178\n",
      "[15,   150] Cum loss: 0.000089\n",
      "[16,    50] Cum loss: 0.000238\n",
      "[16,   100] Cum loss: 0.000153\n",
      "[16,   150] Cum loss: 0.000300\n",
      "[17,    50] Cum loss: 0.000391\n",
      "[17,   100] Cum loss: 0.000405\n",
      "[17,   150] Cum loss: 0.001317\n",
      "[18,    50] Cum loss: 0.000206\n",
      "[18,   100] Cum loss: 0.000374\n",
      "[18,   150] Cum loss: 0.000594\n",
      "[19,    50] Cum loss: 0.000472\n",
      "[19,   100] Cum loss: 0.000819\n",
      "[19,   150] Cum loss: 0.016971\n",
      "[20,    50] Cum loss: 0.000277\n",
      "[20,   100] Cum loss: 0.000253\n",
      "[20,   150] Cum loss: 0.000230\n",
      "Percentage of predictions within 2 decimal places: 64.36%\n",
      "accuracy received 64.35845213849288\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m64.36    \u001b[0m | \u001b[0m0.153    \u001b[0m | \u001b[0m0.00709  \u001b[0m | \u001b[0m62.06    \u001b[0m | \u001b[0m10.53    \u001b[0m |\n",
      "\n",
      "Convos & dropoutP: 42 10 0.19859226541030967\n",
      "imgres 32 32\n",
      "H_out_1, W_out_1 31 31\n",
      "H_out_2, W_out_2 15 15\n",
      "H_out_3, W_out_4 14 13\n",
      "H_out_4, W_out_4 7 6\n",
      "outputconv2 10\n",
      "LeNet5Blend: total params: 63509\n",
      "Train params: 0.0027476010677727368 0.9\n",
      "[1,    50] Cum loss: 0.811637\n",
      "[1,   100] Cum loss: 0.028921\n",
      "[1,   150] Cum loss: 0.021261\n",
      "[2,    50] Cum loss: 0.008947\n",
      "[2,   100] Cum loss: 0.007804\n",
      "[2,   150] Cum loss: 0.006327\n",
      "[3,    50] Cum loss: 0.002759\n",
      "[3,   100] Cum loss: 0.001677\n",
      "[3,   150] Cum loss: 0.001689\n",
      "[4,    50] Cum loss: 0.001530\n",
      "[4,   100] Cum loss: 0.001209\n",
      "[4,   150] Cum loss: 0.001216\n",
      "[5,    50] Cum loss: 0.000704\n",
      "[5,   100] Cum loss: 0.001444\n",
      "[5,   150] Cum loss: 0.001573\n",
      "[6,    50] Cum loss: 0.000967\n",
      "[6,   100] Cum loss: 0.000690\n",
      "[6,   150] Cum loss: 0.000920\n",
      "[7,    50] Cum loss: 0.000749\n",
      "[7,   100] Cum loss: 0.000716\n",
      "[7,   150] Cum loss: 0.000841\n",
      "[8,    50] Cum loss: 0.001067\n",
      "[8,   100] Cum loss: 0.000710\n",
      "[8,   150] Cum loss: 0.000476\n",
      "[9,    50] Cum loss: 0.000687\n",
      "[9,   100] Cum loss: 0.000869\n",
      "[9,   150] Cum loss: 0.001287\n",
      "[10,    50] Cum loss: 0.000931\n",
      "[10,   100] Cum loss: 0.000575\n",
      "[10,   150] Cum loss: 0.000462\n",
      "[11,    50] Cum loss: 0.000581\n",
      "[11,   100] Cum loss: 0.000361\n",
      "[11,   150] Cum loss: 0.002740\n",
      "[12,    50] Cum loss: 0.000845\n",
      "[12,   100] Cum loss: 0.000649\n",
      "[12,   150] Cum loss: 0.001292\n",
      "[13,    50] Cum loss: 0.000443\n",
      "[13,   100] Cum loss: 0.000655\n",
      "[13,   150] Cum loss: 0.000967\n",
      "[14,    50] Cum loss: 0.000542\n",
      "[14,   100] Cum loss: 0.000422\n",
      "[14,   150] Cum loss: 0.000294\n",
      "[15,    50] Cum loss: 0.002343\n",
      "[15,   100] Cum loss: 0.001546\n",
      "[15,   150] Cum loss: 0.001093\n",
      "[16,    50] Cum loss: 0.001118\n",
      "[16,   100] Cum loss: 0.000376\n",
      "[16,   150] Cum loss: 0.000300\n",
      "[17,    50] Cum loss: 0.000902\n",
      "[17,   100] Cum loss: 0.000259\n",
      "[17,   150] Cum loss: 0.000482\n",
      "[18,    50] Cum loss: 0.003716\n",
      "[18,   100] Cum loss: 0.000539\n",
      "[18,   150] Cum loss: 0.000417\n",
      "[19,    50] Cum loss: 0.000285\n",
      "[19,   100] Cum loss: 0.001468\n",
      "[19,   150] Cum loss: 0.000342\n",
      "[20,    50] Cum loss: 0.001186\n",
      "[20,   100] Cum loss: 0.000291\n",
      "[20,   150] Cum loss: 0.002624\n",
      "Percentage of predictions within 2 decimal places: 2.24%\n",
      "accuracy received 2.240325865580448\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m2.24     \u001b[0m | \u001b[0m0.1986   \u001b[0m | \u001b[0m0.002748 \u001b[0m | \u001b[0m42.11    \u001b[0m | \u001b[0m10.76    \u001b[0m |\n",
      "=========================================================================\n",
      "Iteration 0: \n",
      "\t{'target': 87.78004073319755, 'params': {'dropout_probab': 0.208511002351287, 'learning_rate': 0.007482920440979424, 'output_conv_1': 40.0045749926938, 'output_conv_2': 10.418660581054718}}\n",
      "Iteration 1: \n",
      "\t{'target': 23.828920570264767, 'params': {'dropout_probab': 0.07337794540855652, 'learning_rate': 0.0018310473529191804, 'output_conv_1': 47.45040845510684, 'output_conv_2': 10.764485816344383}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.0, 'params': {'dropout_probab': 0.19838373711533497, 'learning_rate': 0.005849350606030213, 'output_conv_1': 56.76778057613179, 'output_conv_2': 13.481756003174077}}\n",
      "Iteration 3: \n",
      "\t{'target': 100.0, 'params': {'dropout_probab': 0.10222612486575872, 'learning_rate': 0.00890305692751851, 'output_conv_1': 41.09550372791705, 'output_conv_2': 13.363740081427217}}\n",
      "Iteration 4: \n",
      "\t{'target': 45.21384928716905, 'params': {'dropout_probab': 0.20865240118356349, 'learning_rate': 0.006028208456011766, 'output_conv_1': 45.61547754380935, 'output_conv_2': 9.58481191267903}}\n",
      "Iteration 5: \n",
      "\t{'target': 72.30142566191446, 'params': {'dropout_probab': 0.40037228433776834, 'learning_rate': 0.00971435418147458, 'output_conv_1': 52.53696712636972, 'output_conv_2': 13.538580925354513}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.0, 'params': {'dropout_probab': 0.43819457614801915, 'learning_rate': 0.009051459971534628, 'output_conv_1': 43.40176845479112, 'output_conv_2': 8.312438265863058}}\n",
      "Iteration 7: \n",
      "\t{'target': 78.41140529531569, 'params': {'dropout_probab': 0.08491520978228445, 'learning_rate': 0.008903282530864719, 'output_conv_1': 43.93387335332201, 'output_conv_2': 11.368861000040418}}\n",
      "Iteration 8: \n",
      "\t{'target': 91.85336048879837, 'params': {'dropout_probab': 0.47894476507525097, 'learning_rate': 0.005798487564757154, 'output_conv_1': 67.67508455801894, 'output_conv_2': 10.524125048048504}}\n",
      "Iteration 9: \n",
      "\t{'target': 0.0, 'params': {'dropout_probab': 0.34325046384079183, 'learning_rate': 0.008511631047076357, 'output_conv_1': 40.73153109376767, 'output_conv_2': 14.00115451955974}}\n",
      "Iteration 10: \n",
      "\t{'target': 31.771894093686353, 'params': {'dropout_probab': 0.10263124770225562, 'learning_rate': 0.00595281535168478, 'output_conv_1': 43.937020509108166, 'output_conv_2': 11.409673437481164}}\n",
      "Iteration 11: \n",
      "\t{'target': 69.24643584521385, 'params': {'dropout_probab': 0.22127865872773117, 'learning_rate': 0.004721236371406603, 'output_conv_1': 61.91219783142683, 'output_conv_2': 13.95361265260189}}\n",
      "Iteration 12: \n",
      "\t{'target': 41.75152749490835, 'params': {'dropout_probab': 0.31169284313929374, 'learning_rate': 0.0030090208294123733, 'output_conv_1': 78.36378588092728, 'output_conv_2': 14.437480119760004}}\n",
      "Iteration 13: \n",
      "\t{'target': 0.0, 'params': {'dropout_probab': 0.010603136826314419, 'learning_rate': 0.008270931156640491, 'output_conv_1': 78.59422164412753, 'output_conv_2': 13.616584217948764}}\n",
      "Iteration 14: \n",
      "\t{'target': 32.9938900203666, 'params': {'dropout_probab': 0.18220959578371426, 'learning_rate': 0.0012015830002020354, 'output_conv_1': 46.096573847869976, 'output_conv_2': 15.772172191052022}}\n",
      "Iteration 15: \n",
      "\t{'target': 45.621181262729124, 'params': {'dropout_probab': 0.497650103984265, 'learning_rate': 0.003926552552944402, 'output_conv_1': 72.67463931957673, 'output_conv_2': 8.357071657768142}}\n",
      "Iteration 16: \n",
      "\t{'target': 43.78818737270876, 'params': {'dropout_probab': 0.4906156469892826, 'learning_rate': 0.0034337559563296506, 'output_conv_1': 72.35140072279071, 'output_conv_2': 11.572474657030629}}\n",
      "Iteration 17: \n",
      "\t{'target': 0.0, 'params': {'dropout_probab': 0.162437880699506, 'learning_rate': 0.006722032745672147, 'output_conv_1': 56.02020437443671, 'output_conv_2': 14.012438399316835}}\n",
      "Iteration 18: \n",
      "\t{'target': 64.35845213849288, 'params': {'dropout_probab': 0.15295561033522215, 'learning_rate': 0.007089879736117241, 'output_conv_1': 62.05526913099922, 'output_conv_2': 10.526861342834266}}\n",
      "Iteration 19: \n",
      "\t{'target': 2.240325865580448, 'params': {'dropout_probab': 0.19859226541030967, 'learning_rate': 0.0027476010677727368, 'output_conv_1': 42.11423907861771, 'output_conv_2': 10.75961624946352}}\n",
      "{'target': 100.0, 'params': {'dropout_probab': 0.10222612486575872, 'learning_rate': 0.00890305692751851, 'output_conv_1': 41.09550372791705, 'output_conv_2': 13.363740081427217}}\n"
     ]
    }
   ],
   "source": [
    "Optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
